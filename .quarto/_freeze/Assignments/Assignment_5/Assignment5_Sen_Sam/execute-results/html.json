{
  "hash": "5bdf4bafee6e3d1298adc5dde1aa90f4",
  "result": {
    "engine": "knitr",
    "markdown": "# Assignment 5\n**Sam Sen** \n**MUSA 5080** \n\n\n\n## Part 1: Indigo Rideshare Data: Q4 2024\n\n### Download and Adapt Data\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(riem)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'riem' was built under R version 4.5.2\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(lubridate)\nlibrary(tigris)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLinking to GEOS 3.13.1, GDAL 3.11.0, PROJ 9.6.0; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n:::\n\n***We begin by loading the main packages for the analysis. tidyverse and lubridate handle data wrangling and date–time manipulation. riem provides historical weather data from airport stations. I also loaded spatial packages (tigris, sf) and ggplot2 for visualization. I then installed and attached riem to query Philadelphia weather data*** \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego <- read_csv(\"Data/indego-trips-2024-q4.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 299121 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): start_time, end_time, bike_id, trip_route_category, passholder_type...\ndbl (9): trip_id, duration, start_station, start_lat, start_lon, end_station...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(indego)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 299,121\nColumns: 15\n$ trip_id             <dbl> 1050296434, 1050293063, 1050296229, 1050276817, 10…\n$ duration            <dbl> 22, 8, 12, 1, 5, 9, 5, 6, 16, 16, 16, 39, 6, 40, 1…\n$ start_time          <chr> \"10/1/2024 0:00\", \"10/1/2024 0:06\", \"10/1/2024 0:0…\n$ end_time            <chr> \"10/1/2024 0:22\", \"10/1/2024 0:14\", \"10/1/2024 0:1…\n$ start_station       <dbl> 3322, 3166, 3007, 3166, 3075, 3166, 3030, 3010, 33…\n$ start_lat           <dbl> 39.93638, 39.97195, 39.94517, 39.97195, 39.96718, …\n$ start_lon           <dbl> -75.15526, -75.13445, -75.15993, -75.13445, -75.16…\n$ end_station         <dbl> 3375, 3017, 3244, 3166, 3102, 3008, 3203, 3163, 33…\n$ end_lat             <dbl> 39.96036, 39.98003, 39.93865, 39.97195, 39.96759, …\n$ end_lon             <dbl> -75.14020, -75.14371, -75.16674, -75.13445, -75.17…\n$ bike_id             <chr> \"03580\", \"05386\", \"18082\", \"02729\", \"18519\", \"0272…\n$ plan_duration       <dbl> 365, 365, 365, 1, 30, 1, 365, 365, 30, 30, 30, 30,…\n$ trip_route_category <chr> \"One Way\", \"One Way\", \"One Way\", \"Round Trip\", \"On…\n$ passholder_type     <chr> \"Indego365\", \"Indego365\", \"Indego365\", \"Walk-up\", …\n$ bike_type           <chr> \"standard\", \"standard\", \"electric\", \"standard\", \"e…\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(indego)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"trip_id\"             \"duration\"            \"start_time\"         \n [4] \"end_time\"            \"start_station\"       \"start_lat\"          \n [7] \"start_lon\"           \"end_station\"         \"end_lat\"            \n[10] \"end_lon\"             \"bike_id\"             \"plan_duration\"      \n[13] \"trip_route_category\" \"passholder_type\"     \"bike_type\"          \n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime   = mdy_hm(end_time),\n\n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n\n    # Time features\n    week  = week(interval60),\n    dotw  = wday(interval60, label = TRUE),\n    hour  = hour(interval60),\n    date  = as.Date(interval60)\n  )\n\n# Quick check\nglimpse(indego)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 299,121\nColumns: 22\n$ trip_id             <dbl> 1050296434, 1050293063, 1050296229, 1050276817, 10…\n$ duration            <dbl> 22, 8, 12, 1, 5, 9, 5, 6, 16, 16, 16, 39, 6, 40, 1…\n$ start_time          <chr> \"10/1/2024 0:00\", \"10/1/2024 0:06\", \"10/1/2024 0:0…\n$ end_time            <chr> \"10/1/2024 0:22\", \"10/1/2024 0:14\", \"10/1/2024 0:1…\n$ start_station       <dbl> 3322, 3166, 3007, 3166, 3075, 3166, 3030, 3010, 33…\n$ start_lat           <dbl> 39.93638, 39.97195, 39.94517, 39.97195, 39.96718, …\n$ start_lon           <dbl> -75.15526, -75.13445, -75.15993, -75.13445, -75.16…\n$ end_station         <dbl> 3375, 3017, 3244, 3166, 3102, 3008, 3203, 3163, 33…\n$ end_lat             <dbl> 39.96036, 39.98003, 39.93865, 39.97195, 39.96759, …\n$ end_lon             <dbl> -75.14020, -75.14371, -75.16674, -75.13445, -75.17…\n$ bike_id             <chr> \"03580\", \"05386\", \"18082\", \"02729\", \"18519\", \"0272…\n$ plan_duration       <dbl> 365, 365, 365, 1, 30, 1, 365, 365, 30, 30, 30, 30,…\n$ trip_route_category <chr> \"One Way\", \"One Way\", \"One Way\", \"Round Trip\", \"On…\n$ passholder_type     <chr> \"Indego365\", \"Indego365\", \"Indego365\", \"Walk-up\", …\n$ bike_type           <chr> \"standard\", \"standard\", \"electric\", \"standard\", \"e…\n$ start_datetime      <dttm> 2024-10-01 00:00:00, 2024-10-01 00:06:00, 2024-10…\n$ end_datetime        <dttm> 2024-10-01 00:22:00, 2024-10-01 00:14:00, 2024-10…\n$ interval60          <dttm> 2024-10-01, 2024-10-01, 2024-10-01, 2024-10-01, 2…\n$ week                <dbl> 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40…\n$ dotw                <ord> Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, …\n$ hour                <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ date                <date> 2024-10-01, 2024-10-01, 2024-10-01, 2024-10-01, 2…\n```\n\n\n:::\n:::\n\n\n**Next, we converted the trip start and end times to proper datetime objects and binned each trip into an hourly interval (interval60). I also created standard temporal features: week number, day of week, hour of day, and calendar date. These fields form the backbone of the time-series modeling**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrips_panel <- indego %>%\n  group_by(\n    interval60,\n    start_station,\n    start_lat,\n    start_lon\n  ) %>%\n  summarize(\n    Trip_Count = n(),\n    .groups = \"drop\"\n  )\n\nglimpse(trips_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 158,517\nColumns: 5\n$ interval60    <dttm> 2024-10-01, 2024-10-01, 2024-10-01, 2024-10-01, 2024-10…\n$ start_station <dbl> 3007, 3008, 3010, 3025, 3030, 3033, 3041, 3075, 3097, 30…\n$ start_lat     <dbl> 39.94517, 39.98081, 39.94711, 39.93724, 39.93935, 39.950…\n$ start_lon     <dbl> -75.15993, -75.15067, -75.16618, -75.16120, -75.15716, -…\n$ Trip_Count    <int> 3, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1,…\n```\n\n\n:::\n:::\n\n\n**I aggregated the raw trip records into a station–hour panel. For each combination of starting station, hour, and location (lat/lon), I counted the number of trips (Trip_Count). This reduces the data from individual trips to a count outcome suitable for demand modelin** \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# How many unique stations and hours do we have?\nn_stations <- length(unique(trips_panel$start_station))\nn_hours    <- length(unique(trips_panel$interval60))\n\nn_stations\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 256\n```\n\n\n:::\n\n```{.r .cell-code}\nn_hours\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2208\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many rows would a complete panel have?\nexpected_rows <- n_stations * n_hours\nexpected_rows\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 565248\n```\n\n\n:::\n\n```{.r .cell-code}\n# Build the full station-hour grid\nstudy_panel <- expand.grid(\n  interval60    = sort(unique(trips_panel$interval60)),\n  start_station = sort(unique(trips_panel$start_station))\n) %>%\n  # Bring in the observed trip counts + lat/lon\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Any missing Trip_Count means 0 trips in that hour at that station\n  mutate(\n    Trip_Count = replace_na(Trip_Count, 0)\n  )\n\nglimpse(study_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 565,248\nColumns: 5\n$ interval60    <dttm> 2024-10-01 00:00:00, 2024-10-01 01:00:00, 2024-10-01 02…\n$ start_station <dbl> 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 30…\n$ start_lat     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ start_lon     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Trip_Count    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Build station attributes (one row per station)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    .groups = \"drop\"\n  )\n\nglimpse(station_attributes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 256\nColumns: 3\n$ start_station <dbl> 3000, 3005, 3006, 3007, 3008, 3009, 3010, 3012, 3014, 30…\n$ start_lat     <dbl> 39.91591, 39.94733, 39.95220, 39.94517, 39.98081, 39.955…\n$ start_lon     <dbl> -75.18370, -75.14403, -75.20311, -75.15993, -75.15067, -…\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove the mostly-NA lat/lon columns, then join clean ones back\nstudy_panel <- study_panel %>%\n  select(-start_lat, -start_lon) %>%   # drop old ones\n  left_join(station_attributes, by = \"start_station\")\n\nglimpse(study_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 565,248\nColumns: 5\n$ interval60    <dttm> 2024-10-01 00:00:00, 2024-10-01 01:00:00, 2024-10-01 02…\n$ start_station <dbl> 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 30…\n$ Trip_Count    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ start_lat     <dbl> 39.91591, 39.91591, 39.91591, 39.91591, 39.91591, 39.915…\n$ start_lon     <dbl> -75.1837, -75.1837, -75.1837, -75.1837, -75.1837, -75.18…\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  mutate(\n    week    = week(interval60),\n    month   = month(interval60, label = TRUE),\n    dotw    = wday(interval60, label = TRUE),\n    hour    = hour(interval60),\n    date    = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n\nglimpse(study_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 565,248\nColumns: 12\n$ interval60    <dttm> 2024-10-01 00:00:00, 2024-10-01 01:00:00, 2024-10-01 02…\n$ start_station <dbl> 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 30…\n$ Trip_Count    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ start_lat     <dbl> 39.91591, 39.91591, 39.91591, 39.91591, 39.91591, 39.915…\n$ start_lon     <dbl> -75.1837, -75.1837, -75.1837, -75.1837, -75.1837, -75.18…\n$ week          <dbl> 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, …\n$ month         <ord> Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, O…\n$ dotw          <ord> Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, T…\n$ hour          <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ date          <date> 2024-10-01, 2024-10-01, 2024-10-01, 2024-10-01, 2024-10…\n$ weekend       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ rush_hour     <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,…\n```\n\n\n:::\n:::\n\n**I created a separate station-level table with one record per start_station, storing its latitude and longitude. I then rejoined these attributes back into the full panel so that every station–hour row has consistent, non-missing coordinates for mapping and spatial analysis** \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get weather from Philly airport (KPHL) for Q4 2024\nweather_data <- riem_measures(\n  station    = \"PHL\",          # Philadelphia International Airport\n  date_start = \"2024-10-01\",\n  date_end   = \"2024-12-31\"\n)\n\n# Process into hourly summaries\nweather_panel <- weather_data %>%\n  mutate(\n    interval60   = floor_date(valid, unit = \"hour\"),\n    Temperature  = tmpf,                      # temp in F\n    Precipitation = ifelse(is.na(p01i), 0, p01i),\n    Wind_Speed   = sknt\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct()\n\nglimpse(weather_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 2,554\nColumns: 4\n$ interval60    <dttm> 2024-10-01 00:00:00, 2024-10-01 01:00:00, 2024-10-01 02…\n$ Temperature   <dbl> 67.0, 65.0, 65.0, 65.0, 65.0, 64.0, 64.4, 64.0, 64.4, 64…\n$ Precipitation <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Wind_Speed    <dbl> 10, 8, 6, 8, 8, 6, 5, 6, 7, 6, 7, 9, 7, 10, 8, 9, 10, 9,…\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(weather_panel$Temperature)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.00   41.00   51.00   50.80   60.95   83.00 \n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  left_join(weather_panel, by = \"interval60\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in left_join(., weather_panel, by = \"interval60\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 7 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(study_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 659,968\nColumns: 15\n$ interval60    <dttm> 2024-10-01 00:00:00, 2024-10-01 01:00:00, 2024-10-01 02…\n$ start_station <dbl> 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 30…\n$ Trip_Count    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ start_lat     <dbl> 39.91591, 39.91591, 39.91591, 39.91591, 39.91591, 39.915…\n$ start_lon     <dbl> -75.1837, -75.1837, -75.1837, -75.1837, -75.1837, -75.18…\n$ week          <dbl> 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, …\n$ month         <ord> Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, O…\n$ dotw          <ord> Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, T…\n$ hour          <int> 0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 10, 10, 11, 12, 13, …\n$ date          <date> 2024-10-01, 2024-10-01, 2024-10-01, 2024-10-01, 2024-10…\n$ weekend       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ rush_hour     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,…\n$ Temperature   <dbl> 67.0, 65.0, 65.0, 65.0, 65.0, 64.0, 64.4, 64.0, 64.4, 64…\n$ Precipitation <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Wind_Speed    <dbl> 10, 8, 6, 8, 8, 6, 5, 6, 7, 6, 7, 9, 7, 10, 8, 9, 10, 9,…\n```\n\n\n:::\n:::\n\n\n**To avoid missing time periods, I constructed a complete grid of all station–hour combinations present in Q4 2024. I joined the observed trip counts onto this grid and set any missing Trip_Count values to zero. This ensures that the model sees both busy and idle hours for each station** \n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60) %>%   # sort correctly\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour   = lag(Trip_Count, 1),\n    lag2Hours  = lag(Trip_Count, 2),\n    lag3Hours  = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day    = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\nglimpse(study_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 659,968\nColumns: 20\n$ interval60    <dttm> 2024-10-01 00:00:00, 2024-10-01 01:00:00, 2024-10-01 02…\n$ start_station <dbl> 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 30…\n$ Trip_Count    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ start_lat     <dbl> 39.91591, 39.91591, 39.91591, 39.91591, 39.91591, 39.915…\n$ start_lon     <dbl> -75.1837, -75.1837, -75.1837, -75.1837, -75.1837, -75.18…\n$ week          <dbl> 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, …\n$ month         <ord> Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, O…\n$ dotw          <ord> Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, T…\n$ hour          <int> 0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 10, 10, 11, 12, 13, …\n$ date          <date> 2024-10-01, 2024-10-01, 2024-10-01, 2024-10-01, 2024-10…\n$ weekend       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ rush_hour     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,…\n$ Temperature   <dbl> 67.0, 65.0, 65.0, 65.0, 65.0, 64.0, 64.4, 64.0, 64.4, 64…\n$ Precipitation <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Wind_Speed    <dbl> 10, 8, 6, 8, 8, 6, 5, 6, 7, 6, 7, 9, 7, 10, 8, 9, 10, 9,…\n$ lag1Hour      <int> NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ lag2Hours     <int> NA, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ lag3Hours     <int> NA, NA, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lag12Hours    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, 0, 0,…\n$ lag1day       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n```\n\n\n:::\n:::\n\n\n**To capture persistence in demand, I created several lagged features for each station: trips 1, 2, and 3 hours ago, 12 hours ago, and 24 hours ago (lag1day). These lags help the model learn that current demand often depends on recent demand at the same station**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel_complete <- study_panel %>%\n  filter(\n    !is.na(lag1Hour),\n    !is.na(lag2Hours),\n    !is.na(lag3Hours),\n    !is.na(lag12Hours),\n    !is.na(lag1day)\n  )\n\nglimpse(study_panel_complete)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 653,824\nColumns: 20\n$ interval60    <dttm> 2024-10-01 18:00:00, 2024-10-01 19:00:00, 2024-10-01 20…\n$ start_station <dbl> 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 30…\n$ Trip_Count    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ start_lat     <dbl> 39.91591, 39.91591, 39.91591, 39.91591, 39.91591, 39.915…\n$ start_lon     <dbl> -75.1837, -75.1837, -75.1837, -75.1837, -75.1837, -75.18…\n$ week          <dbl> 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, …\n$ month         <ord> Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, O…\n$ dotw          <ord> Tue, Tue, Tue, Tue, Tue, Tue, Wed, Wed, Wed, Wed, Wed, W…\n$ hour          <int> 18, 19, 20, 21, 22, 23, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10…\n$ date          <date> 2024-10-01, 2024-10-01, 2024-10-01, 2024-10-01, 2024-10…\n$ weekend       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ rush_hour     <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,…\n$ Temperature   <dbl> 73, 71, 70, 68, 67, 65, 64, 64, 63, 62, 62, 63, 63, 62, …\n$ Precipitation <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Wind_Speed    <dbl> 13, 10, 11, 9, 12, 9, 9, 8, 6, 6, 7, 7, 7, 5, 8, 7, 6, 6…\n$ lag1Hour      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lag2Hours     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lag3Hours     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lag12Hours    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lag1day       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n```\n\n\n:::\n:::\n\n**Because lagged variables are undefined for the first few hours at each station, I removed rows with missing lag values. The resulting study_panel_complete starts after the first full day of data and has all lag features populated, which is necessary for modeling**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Temporal train/test split for Q4 2024\ntrain <- study_panel_complete %>%\n  filter(week < 50)\n\ntest <- study_panel_complete %>%\n  filter(week >= 50)\n\n# Basic checks\nnrow(train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 461056\n```\n\n\n:::\n\n```{.r .cell-code}\nnrow(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 192768\n```\n\n\n:::\n\n```{.r .cell-code}\nmin(train$date); max(train$date)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-10-01\"\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-12-08\"\n```\n\n\n:::\n\n```{.r .cell-code}\nmin(test$date);  max(test$date)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-12-09\"\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-12-31\"\n```\n\n\n:::\n:::\n\n\n### Model Creation\n**I split the data into a training set (weeks 40–49) and a test set (weeks 50–52). This temporal split avoids leaking future information into the past and mimics a real-world forecasting scenario where we train on earlier weeks and evaluate on later weeks in the same quarter**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# In the training data: make a clean day-of-week factor\ntrain <- train %>%\n  mutate(\n    dotw_simple = factor(\n      dotw,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\n    )\n  )\n\n# Set dummy (treatment) coding for dotw_simple\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\n# Quick check\ntable(train$dotw_simple)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  Mon   Tue   Wed   Thu   Fri   Sat   Sun \n61952 62976 63488 78848 65536 66048 62208 \n```\n\n\n:::\n:::\n\n**In the training data, I created a clean day-of-week factor (dotw_simple) with an explicit ordering from Monday to Sunday and set treatment/dummy coding. This makes the interpretation of day-of-week coefficients more straightforward in the linear model**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +        # hour of day\n    dotw_simple +            # day of week\n    Temperature + \n    Precipitation,\n  data = train\n)\n\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation, data = train)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.711 -0.664 -0.224  0.170 41.412 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       -0.4879190  0.0132141 -36.924  < 2e-16 ***\nas.factor(hour)1  -0.0502730  0.0124199  -4.048 5.17e-05 ***\nas.factor(hour)2  -0.0721180  0.0122118  -5.906 3.52e-09 ***\nas.factor(hour)3  -0.1028604  0.0121784  -8.446  < 2e-16 ***\nas.factor(hour)4  -0.0676706  0.0120927  -5.596 2.19e-08 ***\nas.factor(hour)5   0.0366964  0.0121475   3.021  0.00252 ** \nas.factor(hour)6   0.2733507  0.0121635  22.473  < 2e-16 ***\nas.factor(hour)7   0.5347557  0.0123694  43.232  < 2e-16 ***\nas.factor(hour)8   0.8718939  0.0121281  71.890  < 2e-16 ***\nas.factor(hour)9   0.6413455  0.0122134  52.512  < 2e-16 ***\nas.factor(hour)10  0.5390424  0.0120547  44.716  < 2e-16 ***\nas.factor(hour)11  0.5738945  0.0120656  47.565  < 2e-16 ***\nas.factor(hour)12  0.6673419  0.0119663  55.768  < 2e-16 ***\nas.factor(hour)13  0.6486852  0.0118736  54.633  < 2e-16 ***\nas.factor(hour)14  0.6664187  0.0119192  55.911  < 2e-16 ***\nas.factor(hour)15  0.8001032  0.0122984  65.058  < 2e-16 ***\nas.factor(hour)16  0.9396023  0.0120761  77.807  < 2e-16 ***\nas.factor(hour)17  1.1311420  0.0121626  93.001  < 2e-16 ***\nas.factor(hour)18  0.8160769  0.0122484  66.627  < 2e-16 ***\nas.factor(hour)19  0.5285249  0.0122872  43.014  < 2e-16 ***\nas.factor(hour)20  0.3154833  0.0123740  25.496  < 2e-16 ***\nas.factor(hour)21  0.2157332  0.0123962  17.403  < 2e-16 ***\nas.factor(hour)22  0.1643289  0.0123370  13.320  < 2e-16 ***\nas.factor(hour)23  0.0747512  0.0124199   6.019 1.76e-09 ***\ndotw_simple2       0.0608134  0.0066102   9.200  < 2e-16 ***\ndotw_simple3       0.0603034  0.0065983   9.139  < 2e-16 ***\ndotw_simple4      -0.0502359  0.0063232  -7.945 1.95e-15 ***\ndotw_simple5      -0.0138822  0.0065752  -2.111  0.03475 *  \ndotw_simple6      -0.0341312  0.0065498  -5.211 1.88e-07 ***\ndotw_simple7      -0.0525136  0.0066632  -7.881 3.25e-15 ***\nTemperature        0.0122837  0.0001549  79.281  < 2e-16 ***\nPrecipitation     -1.0872688  0.0787122 -13.813  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.167 on 461024 degrees of freedom\nMultiple R-squared:  0.1082,\tAdjusted R-squared:  0.1081 \nF-statistic:  1804 on 31 and 461024 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n**Model 1 is a baseline linear regression that predicts trips per station-hour using only time-of-day, day-of-week, temperature, and precipitation. This captures broad temporal and weather patterns without using any station-specific or lagged information**\n\n**Model 2 extends the baseline by adding lagged demand features: trips 1 hour ago, 3 hours ago, and 24 hours ago. These lags allow the model to use recent station history to refine predictions, capturing short-run momentum or inertia in bike demand**\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain <- study_panel_complete %>% filter(week < 50)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"interval60\"    \"start_station\" \"Trip_Count\"    \"start_lat\"    \n [5] \"start_lon\"     \"week\"          \"month\"         \"dotw\"         \n [9] \"hour\"          \"date\"          \"weekend\"       \"rush_hour\"    \n[13] \"Temperature\"   \"Precipitation\" \"Wind_Speed\"    \"lag1Hour\"     \n[17] \"lag2Hours\"     \"lag3Hours\"     \"lag12Hours\"    \"lag1day\"      \n```\n\n\n:::\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Trip_Count ~ hour + dotw_simple + Temperature + Precipitation +\n#   lag1Hour + lag3Hours + lag1day\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make sure train has the dotw_simple factor\ntrain <- study_panel_complete %>%\n  filter(week < 50) %>%\n  mutate(\n    dotw_simple = factor(\n      dotw,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\n    )\n  )\n\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\n# ---- Model 2: add lag variables ----\nmodel2 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day,\n  data = train\n)\n\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.599  -0.447  -0.118   0.095  32.952 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       -0.1810617  0.0113721 -15.922  < 2e-16 ***\nas.factor(hour)1  -0.0133533  0.0106606  -1.253 0.210356    \nas.factor(hour)2  -0.0062801  0.0104845  -0.599 0.549183    \nas.factor(hour)3  -0.0281245  0.0104592  -2.689 0.007167 ** \nas.factor(hour)4  -0.0033135  0.0103894  -0.319 0.749777    \nas.factor(hour)5   0.0560036  0.0104446   5.362 8.24e-08 ***\nas.factor(hour)6   0.2334064  0.0104667  22.300  < 2e-16 ***\nas.factor(hour)7   0.3798211  0.0106563  35.643  < 2e-16 ***\nas.factor(hour)8   0.5790912  0.0104691  55.314  < 2e-16 ***\nas.factor(hour)9   0.2355823  0.0105440  22.343  < 2e-16 ***\nas.factor(hour)10  0.1905111  0.0103843  18.346  < 2e-16 ***\nas.factor(hour)11  0.2305205  0.0103988  22.168  < 2e-16 ***\nas.factor(hour)12  0.3284782  0.0103097  31.861  < 2e-16 ***\nas.factor(hour)13  0.3003943  0.0102326  29.357  < 2e-16 ***\nas.factor(hour)14  0.3269017  0.0102687  31.835  < 2e-16 ***\nas.factor(hour)15  0.4282957  0.0106001  40.405  < 2e-16 ***\nas.factor(hour)16  0.5175740  0.0104224  49.660  < 2e-16 ***\nas.factor(hour)17  0.6247796  0.0105182  59.400  < 2e-16 ***\nas.factor(hour)18  0.2804317  0.0105993  26.458  < 2e-16 ***\nas.factor(hour)19  0.1344979  0.0105990  12.690  < 2e-16 ***\nas.factor(hour)20  0.0164061  0.0106779   1.536 0.124429    \nas.factor(hour)21  0.0376574  0.0106632   3.532 0.000413 ***\nas.factor(hour)22  0.0538449  0.0105956   5.082 3.74e-07 ***\nas.factor(hour)23  0.0192831  0.0106611   1.809 0.070494 .  \ndotw_simple2       0.0027613  0.0056761   0.486 0.626627    \ndotw_simple3      -0.0167901  0.0056712  -2.961 0.003070 ** \ndotw_simple4      -0.0440361  0.0054285  -8.112 4.99e-16 ***\ndotw_simple5      -0.0442213  0.0056486  -7.829 4.94e-15 ***\ndotw_simple6      -0.0420728  0.0056238  -7.481 7.38e-14 ***\ndotw_simple7      -0.0577401  0.0057222 -10.091  < 2e-16 ***\nTemperature        0.0036953  0.0001348  27.407  < 2e-16 ***\nPrecipitation     -0.9640625  0.0676200 -14.257  < 2e-16 ***\nlag1Hour           0.3430462  0.0013896 246.864  < 2e-16 ***\nlag3Hours          0.1132067  0.0013535  83.641  < 2e-16 ***\nlag1day            0.2125180  0.0012972 163.826  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.002 on 461021 degrees of freedom\nMultiple R-squared:  0.343,\tAdjusted R-squared:  0.343 \nF-statistic:  7080 on 34 and 461021 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day +\n    as.factor(start_station),\n  data = train\n)\n\nsummary(model4)$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3677229\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day +\n    as.factor(start_station) +\n    rush_hour * weekend,   # interaction term\n  data = train\n)\n\nsummary(model5)$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3710861\n```\n\n\n:::\n:::\n\n\n**Model 4 adds station fixed effects via as.factor(start_station). This lets each station have its own baseline level of demand, controlling for unobserved factors like land use, nearby transit, or neighborhood characteristics that are constant over time within the quarter**\n\n**Model 5 keeps the station fixed effects and lag structure and adds an interaction between rush_hour and weekend. This allows the effect of rush-hour periods to differ between weekdays and weekends, reflecting the idea that commuting peaks may be weaker or absent on weekends**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Recreate dotw_simple inside test\ntest <- test %>%\n  mutate(\n    dotw_simple = factor(\n      dotw,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\n    )\n  )\n\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\n# Generate predictions\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There were 4 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `pred1 = predict(model1, newdata = test)`.\nCaused by warning:\n! contrasts dropped from factor dotw_simple\nℹ Run `dplyr::last_dplyr_warnings()` to see the 3 remaining warnings.\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 25\n  interval60          start_station Trip_Count start_lat start_lon  week month\n  <dttm>                      <dbl>      <int>     <dbl>     <dbl> <dbl> <ord>\n1 2024-12-09 00:00:00          3000          0      39.9     -75.2    50 Dec  \n2 2024-12-09 01:00:00          3000          0      39.9     -75.2    50 Dec  \n3 2024-12-09 02:00:00          3000          0      39.9     -75.2    50 Dec  \n4 2024-12-09 03:00:00          3000          0      39.9     -75.2    50 Dec  \n5 2024-12-09 04:00:00          3000          0      39.9     -75.2    50 Dec  \n6 2024-12-09 05:00:00          3000          0      39.9     -75.2    50 Dec  \n# ℹ 18 more variables: dotw <ord>, hour <int>, date <date>, weekend <dbl>,\n#   rush_hour <dbl>, Temperature <dbl>, Precipitation <dbl>, Wind_Speed <dbl>,\n#   lag1Hour <int>, lag2Hours <int>, lag3Hours <int>, lag12Hours <int>,\n#   lag1day <int>, dotw_simple <ord>, pred1 <dbl>, pred2 <dbl>, pred4 <dbl>,\n#   pred5 <dbl>\n```\n\n\n:::\n:::\n\n\n**I recreated the same day-of-week factor in the test set to match the training coding and then generated out-of-sample predictions from all four models (1, 2, 4, and 5). These predictions are stored as pred1, pred2, pred4, and pred5 for later error analysis**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmae_results <- tibble(\n  Model = c(\n    \"Model 1: Time + Weather\",\n    \"Model 2: + Lags\",\n    \"Model 4: + Station FE\",\n    \"Model 5: + Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nmae_results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  Model                     MAE\n  <chr>                   <dbl>\n1 Model 1: Time + Weather 0.529\n2 Model 2: + Lags         0.386\n3 Model 4: + Station FE   0.426\n4 Model 5: + Interaction  0.428\n```\n\n\n:::\n:::\n\n\n### MAE and Result Comparison \n**I evaluated each model’s predictive performance on the test weeks using mean absolute error (MAE) in trips per station-hour. Model 2 (with lags) achieved the lowest MAE, while the more complex models with station fixed effects and interactions did not further reduce test error, suggesting some overfitting.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    error_model2 = Trip_Count - pred2,\n    abs_error_model2 = abs(error_model2),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      TRUE ~ \"Evening\"\n    ),\n    weekend_label = ifelse(weekend == 1, \"Weekend\", \"Weekday\")\n  )\n\nglimpse(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 192,768\nColumns: 29\n$ interval60       <dttm> 2024-12-09 00:00:00, 2024-12-09 01:00:00, 2024-12-09…\n$ start_station    <dbl> 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000,…\n$ Trip_Count       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,…\n$ start_lat        <dbl> 39.91591, 39.91591, 39.91591, 39.91591, 39.91591, 39.…\n$ start_lon        <dbl> -75.1837, -75.1837, -75.1837, -75.1837, -75.1837, -75…\n$ week             <dbl> 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5…\n$ month            <ord> Dec, Dec, Dec, Dec, Dec, Dec, Dec, Dec, Dec, Dec, Dec…\n$ dotw             <ord> Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon…\n$ hour             <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, …\n$ date             <date> 2024-12-09, 2024-12-09, 2024-12-09, 2024-12-09, 2024…\n$ weekend          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ rush_hour        <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,…\n$ Temperature      <dbl> 53.0, 47.0, 46.0, 40.0, 41.0, 39.0, 38.0, 35.0, 38.0,…\n$ Precipitation    <dbl> 0e+00, 0e+00, 0e+00, 0e+00, 0e+00, 0e+00, 0e+00, 0e+0…\n$ Wind_Speed       <dbl> 5, 4, 3, 0, 3, 3, 3, 0, 0, 0, 6, 0, 4, 0, 4, 0, 3, 3,…\n$ lag1Hour         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,…\n$ lag2Hours        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,…\n$ lag3Hours        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lag12Hours       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lag1day          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ dotw_simple      <ord> Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon…\n$ pred1            <dbl> 0.163116969, 0.039141761, 0.005013041, -0.099431449, …\n$ pred2            <dbl> 0.01478892, -0.02073618, -0.01735821, -0.06137443, -0…\n$ pred4            <dbl> -0.233794952, -0.289921904, -0.296658732, -0.35659619…\n$ pred5            <dbl> -0.26141249, -0.31992072, -0.32622711, -0.38540208, -…\n$ error_model2     <dbl> -0.01478892, 0.02073618, 0.01735821, 0.06137443, 0.03…\n$ abs_error_model2 <dbl> 0.01478892, 0.02073618, 0.01735821, 0.06137443, 0.032…\n$ time_of_day      <chr> \"Overnight\", \"Overnight\", \"Overnight\", \"Overnight\", \"…\n$ weekend_label    <chr> \"Weekday\", \"Weekday\", \"Weekday\", \"Weekday\", \"Weekday\"…\n```\n\n\n:::\n:::\n\n**Focusing on Model 2 (the best-performing model), I computed residuals (error_model2) and absolute errors (abs_error_model2) for each station-hour in the test set. I also grouped hours into broader time-of-day buckets (Overnight, AM Rush, Mid-Day, PM Rush, Evening) and labeled each record as Weekend or Weekday to study temporal error patterns** \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.15, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend_label ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Trips (Model 2)\",\n    subtitle = \"Faceted by Weekend/Weekday and Time of Day\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 6144 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 6144 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Assignment5_Sen_Sam_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n## Part II: Error Analysis \n### Spatial Patterns\n\n::: {.cell}\n\n```{.r .cell-code}\nstation_errors <- test %>%\n  group_by(start_station, start_lat, start_lon) %>%\n  summarize(\n    MAE = mean(abs_error_model2, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nglimpse(station_errors)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 256\nColumns: 5\n$ start_station <dbl> 3000, 3005, 3006, 3007, 3008, 3009, 3010, 3012, 3014, 30…\n$ start_lat     <dbl> 39.91591, 39.94733, 39.95220, 39.94517, 39.98081, 39.955…\n$ start_lon     <dbl> -75.18370, -75.14403, -75.20311, -75.15993, -75.15067, -…\n$ MAE           <dbl> 0.1969320, 0.4098259, 0.3811196, 0.6119506, 0.3124952, 0…\n$ avg_demand    <dbl> 0.01460823, 0.27490040, 0.26826029, 0.69986720, 0.152722…\n```\n\n\n:::\n:::\n\n\n**To examine spatial patterns in prediction error, I aggregated the test-set errors to the station level. For each station, I calculated the MAE of Model 2 and the average demand in the test period. This creates a station-level dataset (station_errors) that can be visualized on a map**\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(tigris_use_cache = TRUE)\n\nphilly_boundary <- places(\n  state = \"PA\",\n  cb = TRUE,\n  year = 2023\n) %>%\n  filter(NAME == \"Philadelphia\") %>%\n  st_transform(4326)   # match lon/lat CRS\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  # Philly polygon background\n  geom_sf(\n    data = philly_boundary,\n    fill = \"grey95\",\n    color = \"white\",\n    linewidth = 0.3\n  ) +\n  # Station error points\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon, y = start_lat, color = MAE),\n    size = 2,\n    alpha = 0.9\n  ) +\n  scale_color_viridis_c(option = \"plasma\", direction = -1) +\n  coord_sf(expand = FALSE) +\n  labs(\n    title = \"Spatial Distribution of Prediction Errors (Model 2)\",\n    subtitle = \"MAE per Station – Q4 2024\",\n    color = \"MAE\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.title = element_blank(),\n    axis.text  = element_blank(),\n    axis.ticks = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](Assignment5_Sen_Sam_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n**Finally, I mapped Model 2’s MAE by station using each station’s longitude and latitude. Each point represents a station, colored by its mean absolute error in the test period. This “MAE map” highlights spatial clusters where the model systematically under- or over-performs, which helps identify neighborhoods where additional features or different modeling approaches may be needed.The spatial distribution of Model 2’s prediction errors reveals a clear pattern across Philadelphia. The highest MAE values occur in and around Center City and University City, where trip activity is more variable and influenced by commuting, tourism, dining, and university schedules. These areas experience sharper peaks and dips in demand, making them more difficult to predict using time, weather, and lag-based features alone.In contrast, lower MAE values appear in many outer neighborhoods such as South Philly, Northwest Philly, and parts of West Philly, where trip volumes tend to be more stable, dominated by routine local travel, or close to zero during many hours. Because these stations have more consistent patterns—or are often inactive—the model performs more accurately.Overall, the map suggests that high-activity, mixed-use areas create the greatest forecasting challenges, while residential or low-activity neighborhoods yield more predictable, lower-error demand patterns. This spatial clustering of errors points to potential opportunities for feature engineering focused on employment centers, universities, and event-driven stations**\n\n### Temporal Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend_label) %>%\n  summarize(\n    MAE = mean(abs_error_model2, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = weekend_label)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Temporal Error Patterns (Model 2)\",\n    subtitle = \"MAE by Time of Day and Weekday/Weekend\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error\",\n    fill = \"Day Type\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Assignment5_Sen_Sam_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n**The temporal error analysis shows that Model 2 performs unevenly across different times of day. Prediction errors are highest during the AM and PM rush periods, particularly on weekdays, when commuting patterns create sharp spikes in demand that are harder for the model to capture. Mid-day and evening periods show moderate error levels, reflecting more stable leisure and errand travel.Overnight hours have the lowest errors for both weekdays and weekends because most stations have near-zero demand during this period, making predictions easier. The fact that weekend rush periods exhibit lower MAE than weekday rush periods suggests that weekend bike usage is less peaky, more uniform, and therefore easier to forecast. Overall, the model struggles most during high-volume, high-variability commuting hours.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel_complete <- study_panel_complete %>%\n  mutate(\n    # Feature 1: Feels-like temperature\n    feels_like = Temperature - 0.1 * Wind_Speed,\n\n    # Feature 2: Nice-weather indicator\n    nice_weather = ifelse(Temperature >= 50 & Precipitation == 0, 1, 0)\n  )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain <- study_panel_complete %>%\n  filter(week < 50) %>%\n  mutate(\n    dotw_simple = factor(\n      dotw,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\n    )\n  )\n\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\ntest <- study_panel_complete %>%\n  filter(week >= 50) %>%\n  mutate(\n    dotw_simple = factor(\n      dotw,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\n    )\n  )\n\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel6 <- lm(\n  Trip_Count ~ \n    as.factor(hour) +\n    dotw_simple +\n    Temperature +\n    Precipitation +\n    lag1Hour +\n    lag3Hours +\n    lag1day +\n    feels_like +\n    nice_weather,\n  data = train\n)\n\nsummary(model6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day + feels_like + \n    nice_weather, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.574  -0.446  -0.117   0.097  32.974 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       -1.513e-01  1.310e-02 -11.551  < 2e-16 ***\nas.factor(hour)1  -1.488e-02  1.067e-02  -1.395 0.162887    \nas.factor(hour)2  -8.204e-03  1.049e-02  -0.782 0.434191    \nas.factor(hour)3  -3.059e-02  1.053e-02  -2.905 0.003667 ** \nas.factor(hour)4  -5.929e-03  1.042e-02  -0.569 0.569289    \nas.factor(hour)5   5.213e-02  1.047e-02   4.978 6.44e-07 ***\nas.factor(hour)6   2.299e-01  1.050e-02  21.890  < 2e-16 ***\nas.factor(hour)7   3.750e-01  1.069e-02  35.082  < 2e-16 ***\nas.factor(hour)8   5.741e-01  1.051e-02  54.600  < 2e-16 ***\nas.factor(hour)9   2.305e-01  1.059e-02  21.769  < 2e-16 ***\nas.factor(hour)10  1.862e-01  1.041e-02  17.875  < 2e-16 ***\nas.factor(hour)11  2.263e-01  1.043e-02  21.693  < 2e-16 ***\nas.factor(hour)12  3.266e-01  1.033e-02  31.623  < 2e-16 ***\nas.factor(hour)13  3.016e-01  1.024e-02  29.455  < 2e-16 ***\nas.factor(hour)14  3.309e-01  1.029e-02  32.160  < 2e-16 ***\nas.factor(hour)15  4.322e-01  1.062e-02  40.696  < 2e-16 ***\nas.factor(hour)16  5.232e-01  1.047e-02  49.992  < 2e-16 ***\nas.factor(hour)17  6.333e-01  1.061e-02  59.703  < 2e-16 ***\nas.factor(hour)18  2.892e-01  1.069e-02  27.060  < 2e-16 ***\nas.factor(hour)19  1.423e-01  1.068e-02  13.330  < 2e-16 ***\nas.factor(hour)20  2.303e-02  1.074e-02   2.143 0.032075 *  \nas.factor(hour)21  4.095e-02  1.068e-02   3.833 0.000126 ***\nas.factor(hour)22  5.448e-02  1.060e-02   5.138 2.77e-07 ***\nas.factor(hour)23  1.935e-02  1.066e-02   1.815 0.069601 .  \ndotw_simple2       6.808e-04  5.731e-03   0.119 0.905454    \ndotw_simple3      -1.967e-02  5.702e-03  -3.451 0.000559 ***\ndotw_simple4      -4.134e-02  5.447e-03  -7.589 3.23e-14 ***\ndotw_simple5      -4.206e-02  5.659e-03  -7.432 1.07e-13 ***\ndotw_simple6      -4.049e-02  5.671e-03  -7.139 9.39e-13 ***\ndotw_simple7      -6.072e-02  5.749e-03 -10.562  < 2e-16 ***\nTemperature       -1.977e-02  3.526e-03  -5.608 2.04e-08 ***\nPrecipitation     -9.336e-01  6.865e-02 -13.599  < 2e-16 ***\nlag1Hour           3.430e-01  1.390e-03 246.783  < 2e-16 ***\nlag3Hours          1.132e-01  1.354e-03  83.589  < 2e-16 ***\nlag1day            2.124e-01  1.298e-03 163.698  < 2e-16 ***\nfeels_like         2.326e-02  3.510e-03   6.627 3.44e-11 ***\nnice_weather      -4.963e-05  5.055e-03  -0.010 0.992167    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.002 on 460763 degrees of freedom\n  (256 observations deleted due to missingness)\nMultiple R-squared:  0.343,\tAdjusted R-squared:  0.343 \nF-statistic:  6683 on 36 and 460763 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    pred6 = predict(model6, newdata = test)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `pred6 = predict(model6, newdata = test)`.\nCaused by warning:\n! contrasts dropped from factor dotw_simple\n```\n\n\n:::\n\n```{.r .cell-code}\nmae_model6 <- mean(abs(test$Trip_Count - test$pred6), na.rm = TRUE)\nmae_model6\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3869234\n```\n\n\n:::\n:::\n\n\n**I added two new weather-based features to Model 2:(1) Feels-like temperature, capturing wind chill effects, and (2) A “nice-weather” indicator for hours with temperature ≥ 50°F and zero precipitation. After refitting the model (Model 6), the resulting MAE on the Q4 2024 test set was 0.3869, virtually the same as Model 2’s MAE of 0.3860. This suggests that in Q4, when most hours are cold and have low, stable demand, these additional features do not meaningfully improve predictive accuracy.In warmer quarters these features might be more effective, but for Q4 they add little explanatory power because weather conditions vary less and demand is low or zero in many station-hours** \n\n::: {.cell}\n\n:::\n\n\n\nI added two new weather-based features to Model 2:\n(1) Feels-like temperature, capturing wind chill effects, and\n(2) A “nice-weather” indicator for hours with temperature ≥ 50°F and zero precipitation.\n\nAfter refitting the model (Model 6), the resulting MAE on the Q4 2024 test set was 0.3869, virtually the same as Model 2’s MAE of 0.3860. This suggests that in Q4, when most hours are cold and have low, stable demand, these additional features do not meaningfully improve predictive accuracy.\n\nIn warmer quarters these features might be more effective, but for Q4 they add little explanatory power because weather conditions vary less and demand is low or zero in many station-hours.\n\n---\n",
    "supporting": [
      "Assignment5_Sen_Sam_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}