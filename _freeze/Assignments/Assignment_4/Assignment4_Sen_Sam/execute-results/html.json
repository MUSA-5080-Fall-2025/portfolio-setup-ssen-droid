{
  "hash": "b59bc22962ad85e687ac7020b318fb93",
  "result": {
    "engine": "knitr",
    "markdown": "# Lab Assignment 4: Spatial Predictive Analysis\n**MUSA 5080 - Fall 2025**\n**Sam Sen** \n\n---\n\n## Introduction \nThis report will explore Rodent Baiting requests in the Chicago area. I have selected this set to see if there are spatial patterns associated with rodent baiting requests, and understand where requests occur most often. This information could be used to help allocate city resources. It is also important to note that just because a specific area has many requests doesn't necessarily mean that that area suffers more from rodent infestations. This is much like the predicament of predictive policing. It is very possible that wealthier neighborhoods file more complaints while poorer neighborhoods fail to report rodent sightings. This report will not explore additional demographic datasets in order to address these questions, but it is important to keep in mind as this report is analyzed. \n\n## Violation Selection: Rodent Baiting\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(janitor)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'janitor' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n```\n\n\n:::\n\n```{.r .cell-code}\nrodent <- readr::read_csv(\"Data/Rodent.csv\") %>%\n  janitor::clean_names()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 319187 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): Creation Date, Status, Completion Date, Service Request Number, Ty...\ndbl (11): Number of Premises Baited, Number of Premises with Garbage, Number...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(rodent)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 319,187\nColumns: 20\n$ creation_date                   <chr> \"12/18/2018\", \"12/18/2018\", \"12/18/201…\n$ status                          <chr> \"Open\", \"Open\", \"Open\", \"Open\", \"Open\"…\n$ completion_date                 <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ service_request_number          <chr> \"18-03388501\", \"18-03386546\", \"18-0338…\n$ type_of_service_request         <chr> \"Rodent Baiting/Rat Complaint\", \"Roden…\n$ number_of_premises_baited       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ number_of_premises_with_garbage <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ number_of_premises_with_rats    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ current_activity                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ most_recent_action              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ street_address                  <chr> \"2342 S CENTRAL PARK AVE\", \"1609 W WRI…\n$ zip_code                        <dbl> 60623, 60614, 60630, 60613, 60659, 606…\n$ x_coordinate                    <dbl> 1152739, 1165128, 1148914, 1165376, 11…\n$ y_coordinate                    <dbl> 1888202, 1917335, 1929708, 1926101, 19…\n$ ward                            <dbl> 22, 32, 35, 47, 40, 23, 29, 47, 18, 49…\n$ police_district                 <dbl> 10, 19, 17, 19, 20, 8, 25, 19, 8, 24, …\n$ community_area                  <dbl> 30, 7, 14, 6, 2, 56, 25, 6, 70, 1, 70,…\n$ latitude                        <dbl> 41.84908, 41.92877, 41.96305, 41.95282…\n$ longitude                       <dbl> -87.71492, -87.66863, -87.72789, -87.6…\n$ location                        <chr> \"(41.849080332575, -87.714922751048)\",…\n```\n\n\n:::\n\n```{.r .cell-code}\nnrow(rodent)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 319187\n```\n\n\n:::\n:::\n\n### Explanation \nThe violation selection code narrows the massive 311 dataset down to one type of service request and one year of observations.That subset becomes the input for all later steps (fishnet aggregation, modeling, cross-validation, KDE baseline).\n\n\n## Data Loading & Exploration\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Parse the text dates, then keep only 2017 rows with valid coordinates\nrodent_2017 <- rodent %>%\n  mutate(creation_date = lubridate::mdy(creation_date)) %>%  # \"12/18/2018\" -> Date\n  filter(lubridate::year(creation_date) == 2017,              # only 2017\n         !is.na(latitude), !is.na(longitude))                 # drop missing coords\n\n# quick checks\nnrow(rodent_2017)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 50961\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(rodent_2017$creation_date)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        Min.      1st Qu.       Median         Mean      3rd Qu.         Max. \n\"2017-01-01\" \"2017-05-09\" \"2017-07-26\" \"2017-07-15\" \"2017-09-28\" \"2017-12-31\" \n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLinking to GEOS 3.13.1, GDAL 3.11.0, PROJ 9.6.0; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\n# Convert to an sf (spatial) object\nrodent_sf <- st_as_sf(\n  rodent_2017,\n  coords = c(\"longitude\", \"latitude\"),\n  crs = 4326  # WGS84 coordinate system (standard lat/long)\n)\n\n# Check structure\nrodent_sf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 50961 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -87.8859 ymin: 41.64704 xmax: -87.52459 ymax: 42.02253\nGeodetic CRS:  WGS 84\n# A tibble: 50,961 × 19\n   creation_date status    completion_date service_request_number\n * <date>        <chr>     <chr>           <chr>                 \n 1 2017-12-31    Completed 01/02/2018      17-08696363           \n 2 2017-12-31    Completed 01/02/2018      17-08697609           \n 3 2017-12-31    Completed 01/02/2018      17-08697369           \n 4 2017-12-31    Completed 01/02/2018      17-08696116           \n 5 2017-12-31    Completed 01/02/2018      17-08696114           \n 6 2017-12-31    Completed 01/02/2018      17-08691527           \n 7 2017-12-31    Completed 01/03/2018      17-08696318           \n 8 2017-12-31    Completed 01/03/2018      17-08693190           \n 9 2017-12-31    Completed 01/03/2018      17-08704837           \n10 2017-12-31    Completed 01/02/2018      17-08699803           \n# ℹ 50,951 more rows\n# ℹ 15 more variables: type_of_service_request <chr>,\n#   number_of_premises_baited <dbl>, number_of_premises_with_garbage <dbl>,\n#   number_of_premises_with_rats <dbl>, current_activity <chr>,\n#   most_recent_action <chr>, street_address <chr>, zip_code <dbl>,\n#   x_coordinate <dbl>, y_coordinate <dbl>, ward <dbl>, police_district <dbl>,\n#   community_area <dbl>, location <chr>, geometry <POINT [°]>\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# needs: library(ggplot2); library(sf)\n# assumes you already have rodent_sf (2017 points as sf in EPSG:4326)\n\nggplot() +\n  geom_sf(data = rodent_sf, color = \"firebrick\", alpha = 0.15, size = 0.20) +\n  labs(\n    title = \"Rodent Baiting Requests (2017) — Points\",\n    subtitle = \"Each point = one 311 request\",\n    caption = \"Source: City of Chicago 311\"\n  ) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](Assignment4_Sen_Sam_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nrodent_sample <- dplyr::slice_sample(rodent_sf, n = 10000)\n\nggplot() +\n  geom_sf(data = rodent_sample, color = \"firebrick\", alpha = 0.25, size = 0.25) +\n  labs(title = \"Rodent Baiting (2017) — Sample of 10k points\") +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](Assignment4_Sen_Sam_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n### Obersvations \nThere are an alarming number of rodent baiting requests throughout the city of Chicago, with the north side of Chicago in particular looking very dense. However, without a density map, it is hard to differentiate between the dark clusters of red. The south side of Chicago clearly has more sparse data with regard to rodent baiting requests. The following section will employ fishnet grid creation to better understand the spatial data. \n\n## Fishnet Grid Creation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tigris)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(viridis)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: viridisLite\n```\n\n\n:::\n\n```{.r .cell-code}\noptions(tigris_use_cache = TRUE, tigris_class = \"sf\")\n\n# Chicago boundary (robust filter), then keep only the main polygon; project to meters\nil_places <- places(state = \"IL\", cb = TRUE, year = 2020)\nchi_city <- il_places %>%\n  filter(NAME == \"Chicago\" | NAME == \"Chicago city\" | grepl(\"^Chicago\", NAMELSAD)) %>%\n  st_make_valid() %>%\n  st_cast(\"POLYGON\") %>%\n  mutate(area = st_area(.)) %>%\n  slice_max(area, n = 1) %>%\n  st_transform(3857)\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Regular 500 m grid covering Chicago’s extent\ngrid_raw <- st_make_grid(chi_city, cellsize = 500, square = TRUE) %>%\n  st_as_sf() %>%\n  mutate(grid_id = dplyr::row_number())\n\n# Keep only cells whose centroids fall inside the city (drop outside)\ngrid_500 <- grid_raw[ st_within(st_centroid(grid_raw), chi_city, sparse = FALSE)[,1], ]\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: st_centroid assumes attributes are constant over geometries\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ensure points are in meters to match the grid/boundary\nrodent_3857 <- st_transform(rodent_sf, 3857)\n\n# Count points per cell (fast: use st_intersects + lengths)\ngrid_agg <- grid_500 %>%\n  mutate(count = lengths(st_intersects(., rodent_3857)))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbb <- st_bbox(chi_city)\n\n# Map of counts per 500 m cell (sqrt stretch makes mid-range visible)\nggplot() +\n  geom_sf(data = grid_agg, aes(fill = count), color = NA) +\n  geom_sf(data = chi_city, fill = NA, color = \"grey35\", linewidth = 0.4, inherit.aes = FALSE) +\n  coord_sf(crs = 3857,\n           xlim = c(bb[\"xmin\"], bb[\"xmax\"]),\n           ylim = c(bb[\"ymin\"], bb[\"ymax\"]),\n           expand = FALSE) +\n  scale_fill_viridis_c(trans = \"sqrt\", name = \"Requests / cell\") +\n  labs(title = \"Rodent Baiting (2017) — Counts per 500 m Cell\",\n       subtitle = \"Fishnet aggregation across Chicago\",\n       caption = \"Source: City of Chicago 311; Boundary: US Census TIGER/Line\") +\n  theme_void() +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Assignment4_Sen_Sam_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Quick histogram of cell counts (skews right; many zeros, few hotspots)\nggplot(st_drop_geometry(grid_agg), aes(x = count)) +\n  geom_histogram(binwidth = 1, boundary = 0) +\n  scale_y_continuous(labels = scales::comma) +\n  labs(title = \"Distribution of Requests per 500 m Cell\",\n       x = \"Requests in cell\", y = \"Number of cells\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Assignment4_Sen_Sam_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n\n### Obersvations\nThe above fisnhnet aggregation helps smooth over the rodent baiting point map in the previous section by displaying # of requests per grid cell. In essence, we have created a fishnet grid where every 500 square meters is a grid cell. From here, we can look at counts per grid cells rather than just thousands of points which is hard to interpret. This visualization makes it easier to evaluate counts accross space and provides a better sense of density of requests. The above map clearly shows high counts particular clustered in the north side of Chicago. \n\n\n## Spatial Features\nIn this section we will create a k-nearest neighbors feature and look at average counts of each grid cells 5 nearest neighbors. We will equally weight the neighbors counts and compute the average. We will then conduct Local Moran's I analysis in the subsequent section and add our second feature - a distance measure - that will be further explained in that section.   \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(dplyr)\nlibrary(spdep)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spdep' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: spData\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spData' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTo access larger datasets in this package, install the spDataLarge\npackage with: `install.packages('spDataLarge',\nrepos='https://nowosad.github.io/drat/', type='source')`\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_agg_3857 <- st_transform(grid_agg, 3857)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncentroids <- st_centroid(grid_agg_3857)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: st_centroid assumes attributes are constant over geometries\n```\n\n\n:::\n\n```{.r .cell-code}\nxy <- st_coordinates(centroids)\nknn5 <- knearneigh(xy, k = 5)\nnb5  <- knn2nb(knn5)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in knn2nb(knn5): neighbour object has 2 sub-graphs\n```\n\n\n:::\n\n```{.r .cell-code}\nlw5  <- nb2listw(nb5, style = \"W\", zero.policy = TRUE)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert neighbor list into a weights matrix\nweights_5 <- spdep::nb2listw(nb5, style = \"W\")\n\n# Calculate spatial lag (mean count of 5 nearest neighbors)\ngrid_agg_3857$lag5_mean <- spdep::lag.listw(weights_5, grid_agg_3857$count)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(viridis)\n\nggplot(grid_agg_3857) +\n  geom_sf(aes(fill = lag5_mean), color = NA) +\n  scale_fill_viridis_c(name = \"Avg Neighbor Count\", trans = \"sqrt\") +\n  labs(\n    title = \"Rodent Baiting — Mean Count of 5 Nearest Neighbor Cells\",\n    subtitle = \"Spatial lag feature (k = 5)\",\n    caption = \"Source: City of Chicago 311\"\n  ) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](Assignment4_Sen_Sam_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n### Explanation \nThe above map displays our first feature - k-NN. Each grid cell is displaying the mean of its 5 nearest neighbored weighted equally. Visually, there appears to be spatial autocorrelation, with high counts surrounded by high counts and low counts surrounded by low counts. However, statistical significance of this apparent autocorrelation cannot be determined without computing Moran's I. The next step with look at Local Moran's I to evaluate the signifiance of this observed spatial autocorrelation. \n\n## Local Moran's I \n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Local Moran’s I: Hot/Cold Spot Analysis ---\nlibrary(spdep)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n#Compute Local Moran’s I for the counts\nlocI <- localmoran(grid_agg_3857$count, lw5, zero.policy = TRUE)\n\n#Attach results\ngrid_agg_3857 <- grid_agg_3857 %>%\n  mutate(\n    Ii = locI[, 1],          # Local Moran’s I value\n    Ei = locI[, 2],          # Expected value\n    Vi = locI[, 3],          # Variance\n    Z  = (Ii - Ei) / sqrt(Vi), # Z-score\n    Pr = locI[, 5]           # p-value\n  )\n\n#Classify each cell (significant clusters/outliers)\nz_count <- as.numeric(scale(grid_agg_3857$count))\nz_lag   <- as.numeric(scale(grid_agg_3857$lag5_mean))\nsig     <- grid_agg_3857$Pr < 0.05\n\ngrid_agg_3857$quad <- dplyr::case_when(\n  z_count >= 0 & z_lag >= 0 & sig ~ \"High-High (Hot Spot)\",\n  z_count <  0 & z_lag <  0 & sig ~ \"Low-Low (Cold Spot)\",\n  z_count >= 0 & z_lag <  0 & sig ~ \"High-Low (Outlier)\",\n  z_count <  0 & z_lag >= 0 & sig ~ \"Low-High (Outlier)\",\n  TRUE ~ \"Not Significant\"\n)\n\n#Plot hot/cold spots\nggplot(grid_agg_3857) +\n  geom_sf(aes(fill = quad), color = NA) +\n  scale_fill_manual(\n    values = c(\n      \"High-High (Hot Spot)\"  = \"#b2182b\",\n      \"Low-Low (Cold Spot)\"   = \"#2166ac\",\n      \"High-Low (Outlier)\"    = \"#ef8a62\",\n      \"Low-High (Outlier)\"    = \"#67a9cf\",\n      \"Not Significant\"       = \"grey90\"\n    ),\n    name = \"Local Moran’s I\"\n  ) +\n  labs(\n    title    = \"Local Moran’s I — Rodent Baiting Requests (2017)\",\n    subtitle = \"Significant clusters (p < 0.05) using k = 5 nearest neighbors\",\n    caption  = \"Source: City of Chicago 311\"\n  ) +\n  theme_void() +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Assignment4_Sen_Sam_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n### Explanation\nIn general, the clustering of high-high values in the north side of Chicago is significant (hot spots). The Low-low clustering that we observed in the previous map is not spatially significant per Local Moran's I. This could be due to 0s and lack of observations. The north and southwest parts of the city sow clusters of high rodent complaints. These may correspond to dense residential neighborhoods. The central and outer areas show few significant clusters, possibly due to lower population density or lack of reporting due to other factors including demographic. \n\n## Additional Spatial Feature (Distance Measures)\nHere we will add feature and visualization that shows each grid cells distance to the nearest hotspot. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(dplyr)\n\n# 1️⃣ Separate the hot spot cells\nhotspots <- grid_agg_3857 %>% \n  filter(quad == \"High-High (Hot Spot)\")\n\n# 2️⃣ Calculate distance from every cell centroid to nearest hot spot centroid\ncentroids <- st_centroid(grid_agg_3857)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: st_centroid assumes attributes are constant over geometries\n```\n\n\n:::\n\n```{.r .cell-code}\nhot_centroids <- st_centroid(hotspots)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: st_centroid assumes attributes are constant over geometries\n```\n\n\n:::\n\n```{.r .cell-code}\n# st_distance creates a distance matrix (each cell vs each hot spot)\ndist_matrix <- st_distance(centroids, hot_centroids)\n\n# 3️⃣ Take the minimum distance per cell (convert from meters to km)\ngrid_agg_3857$dist_to_hotspot_km <- apply(dist_matrix, 1, min) / 1000\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(viridis)\n\nggplot(grid_agg_3857) +\n  geom_sf(aes(fill = dist_to_hotspot_km), color = NA) +\n  scale_fill_viridis_c(name = \"Distance to nearest hot spot (km)\", trans = \"sqrt\") +\n  labs(\n    title = \"Distance to Nearest Hot Spot — Rodent Baiting (2017)\",\n    subtitle = \"Each 500 m cell colored by distance from significant hot spots\",\n    caption = \"Source: City of Chicago 311; Hot spots from Local Moran’s I\"\n  ) +\n  theme_void() +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Assignment4_Sen_Sam_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n### Explanation \nThe above gradient map shows grid cells that are far from hot spots in light yellow and grid cells that are closer to hotspots in blue. As expected, the south side of Chicago is largely yellow due to the low number of rodent baiting requests, while the north side of Chicago displays dark blue. This can be simply interpreted by saying the south side of Chicago tends to have grid cells that are far away from hotspots and as one moves north their distance to the nearest hotspot decreases. \n\n## Count Regression Models\n\nIn this section we will first fit a Poisson Regression and then a negative binomial regression. We have created two predictors from the previous sections - k-NN and our distance measure - and our dependent variable is the number of rodent baiting reqests in a given grid cell. Since the dependent variable is a count (# of baiting requests) we cannot use simple regresison. \n\n### Poisson Regression \n\n::: {.cell}\n\n```{.r .cell-code}\n# Predictors we created in Part 3:\n# - lag5_mean (avg of 5 nearest neighbors)\n# - dist_to_hotspot_km (distance to nearest hot spot)\n\nstopifnot(all(c(\"count\",\"lag5_mean\",\"dist_to_hotspot_km\") %in% names(grid_agg_3857)))\n\n# (optional but helpful) replace any tiny NAs with 0s for modeling\ngrid_mod <- grid_agg_3857 |>\n  dplyr::mutate(\n    lag5_mean = ifelse(is.na(lag5_mean), 0, lag5_mean),\n    dist_to_hotspot_km = ifelse(is.na(dist_to_hotspot_km), 0, dist_to_hotspot_km)\n  )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Poisson regression with log link (default)\nm_pois <- glm(\n  count ~ lag5_mean + dist_to_hotspot_km,\n  data = grid_mod,\n  family = poisson(link = \"log\")\n)\n\nsummary(m_pois)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = count ~ lag5_mean + dist_to_hotspot_km, family = poisson(link = \"log\"), \n    data = grid_mod)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)         2.2070430  0.0111391  198.14   <2e-16 ***\nlag5_mean           0.0369991  0.0003442  107.49   <2e-16 ***\ndist_to_hotspot_km -0.1524437  0.0023424  -65.08   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 76886  on 4295  degrees of freedom\nResidual deviance: 35345  on 4293  degrees of freedom\nAIC: 48157\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(coef(m_pois))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       (Intercept)          lag5_mean dist_to_hotspot_km \n         9.0888013          1.0376920          0.8586072 \n```\n\n\n:::\n:::\n\n\n### Negative Binomial Regression \n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"MASS\")  # if not installed\nlibrary(MASS)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'MASS'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(broom)\n\nm_nb <- glm.nb(count ~ lag5_mean + dist_to_hotspot_km, data = grid_mod)\nsummary(m_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = count ~ lag5_mean + dist_to_hotspot_km, data = grid_mod, \n    init.theta = 0.9225686614, link = log)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)         1.756127   0.040346   43.53   <2e-16 ***\nlag5_mean           0.059945   0.001744   34.37   <2e-16 ***\ndist_to_hotspot_km -0.123502   0.004981  -24.80   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.9226) family taken to be 1)\n\n    Null deviance: 8810.1  on 4295  degrees of freedom\nResidual deviance: 4957.7  on 4293  degrees of freedom\nAIC: 25949\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.9226 \n          Std. Err.:  0.0263 \n\n 2 x log-likelihood:  -25941.4510 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(m_pois, m_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       df      AIC\nm_pois  3 48156.93\nm_nb    4 25949.45\n```\n\n\n:::\n:::\n\n\n### Explanation \nThe Poisson regression assumes that mean=variance, which is likley unrealistic given that many cells have 0 counts while some cells have extremely high counts. Negative Binomial regression relaxes this assumption by adding a parameter that allows variance to exceed mean. In comparing AICs of both models, the Negative Binomial model appears to be a better fit which is expected given the highy variance in the data.  \n\n## Spatial Cross-Validation (2017)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Part 5 — Step 1: assign each grid cell to a spatial group (Census tract)\n\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tigris)\noptions(tigris_use_cache = TRUE, tigris_class = \"sf\")\n\n#Load Cook County tracts and keep just the tract ID\ncook_tracts <- tigris::tracts(state = \"IL\", county = \"Cook\", cb = TRUE, year = 2017) %>%\n  st_transform(3857) %>%\n  dplyr::select(GEOID)  # explicitly use dplyr::select()\n\n#Get centroids for grid (points for joining)\ngrid_cent <- st_centroid(grid_agg_3857)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: st_centroid assumes attributes are constant over geometries\n```\n\n\n:::\n\n```{.r .cell-code}\n#Spatial join: assign each centroid to its containing tract polygon\ngrid_with_group <- st_join(grid_cent, cook_tracts, left = TRUE)\n\n#Copy GEOID (the tract ID) into grid object as group_id\ngrid_agg_3857$group_id <- grid_with_group$GEOID\n\n#Sanity checks\ncat(\"Unique tracts assigned:\", length(unique(na.omit(grid_agg_3857$group_id))), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnique tracts assigned: 780 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Unassigned cells:\", sum(is.na(grid_agg_3857$group_id)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnassigned cells: 48 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Part 5 — Step 2: define function for one iteration of LOGO CV\n\nlibrary(MASS)     # for glm.nb\nlibrary(Metrics)  # for mae() and rmse()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'Metrics' was built under R version 4.5.2\n```\n\n\n:::\n\n```{.r .cell-code}\nrun_logo <- function(test_group, data) {\n  # Split data into training and testing based on group_id\n  train_data <- data[data$group_id != test_group, ]\n  test_data  <- data[data$group_id == test_group, ]\n  \n  # Fit Negative Binomial model \n  model <- glm.nb(count ~ lag5_mean + dist_to_hotspot_km, data = train_data)\n  \n  # Predict for held-out group\n  preds <- predict(model, newdata = test_data, type = \"response\")\n  \n  # Calculate error metrics for that group\n  data.frame(\n    group_id = test_group,\n    MAE  = mae(test_data$count, preds),\n    RMSE = rmse(test_data$count, preds)\n  )\n}\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Part 5 — Step 3: choose valid test groups (tracts with enough cells)\n\nlibrary(dplyr)\n\n# cells per tract\ngroup_summary <- grid_agg_3857 |>\n  st_drop_geometry() |>\n  filter(!is.na(group_id)) |>\n  count(group_id, name = \"n_cells\")\n\n# distribution of tract sizes (sanity check)\nsize_dist <- group_summary |>\n  count(n_cells, name = \"num_tracts\") |>\n  arrange(n_cells)\nprint(size_dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   n_cells num_tracts\n1        1         61\n2        2        197\n3        3         91\n4        4        138\n5        5         48\n6        6         74\n7        7         24\n8        8         42\n9        9         16\n10      10         22\n11      11          8\n12      12         11\n13      13          6\n14      14          7\n15      15          5\n16      16          4\n17      17          4\n18      18          5\n19      19          1\n20      20          3\n21      21          1\n22      23          1\n23      24          1\n24      25          1\n25      26          1\n26      27          2\n27      37          1\n28      39          1\n29      41          1\n30      52          1\n31     144          1\n32     158          1\n```\n\n\n:::\n\n```{.r .cell-code}\n# pick tracts with >= 5 cells as testable groups\nvalid_groups <- group_summary |>\n  filter(n_cells >= 5) |>\n  pull(group_id)\n\n# dataset restricted to those groups for testing (training will still see ALL groups in each fold)\ngrid_valid <- grid_agg_3857 |>\n  filter(group_id %in% valid_groups)\n\n# quick coverage stats\ncat(\"Total tracts:\", nrow(group_summary), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal tracts: 780 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Valid test tracts (>=5 cells):\", length(valid_groups), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nValid test tracts (>=5 cells): 293 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Cells in valid test tracts:\", nrow(grid_valid), \"of\", nrow(grid_agg_3857), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCells in valid test tracts: 2968 of 4296 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Coverage of cells for testing:\", round(100 * nrow(grid_valid)/nrow(grid_agg_3857), 1), \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoverage of cells for testing: 69.1 %\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Part 5 — Step 4: quick sanity run on 10 valid tracts\ntest_groups <- valid_groups[1:10]\n\ncv_results_small <- do.call(\n  rbind,\n  lapply(test_groups, run_logo, data = grid_valid)\n)\n\n# View first few results and overall averages\nhead(cv_results_small)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     group_id       MAE      RMSE\n1 17031020200  36.31020  43.87495\n2 17031020301  44.50022  54.23567\n3 17031020702  15.72574  24.19855\n4 17031020802 112.69768 145.93005\n5 17031020902  71.48871  96.75528\n6 17031030500 130.06076 149.64516\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(cv_results_small$MAE, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 44.38208\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(cv_results_small$RMSE, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 56.48171\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Part 5 — Step 5: full Leave-One-Group-Out CV over all valid tracts\ncv_results <- do.call(\n  rbind,\n  lapply(valid_groups, run_logo, data = grid_valid)\n)\n\n# Save + summarize\nhead(cv_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     group_id       MAE      RMSE\n1 17031020200  36.31020  43.87495\n2 17031020301  44.50022  54.23567\n3 17031020702  15.72574  24.19855\n4 17031020802 112.69768 145.93005\n5 17031020902  71.48871  96.75528\n6 17031030500 130.06076 149.64516\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(cv_results$MAE, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 14.95117\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(cv_results$RMSE, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 19.47667\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Part 5 — Optional diagnostic: visualize CV errors by tract\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(viridis)\n\n#Summarize mean MAE per tract (from cv_results)\ncv_summary <- cv_results |>\n  group_by(group_id) |>\n  summarise(MAE = mean(MAE, na.rm = TRUE),\n            RMSE = mean(RMSE, na.rm = TRUE))\n\n#️Join CV errors back to the tract geometry\ntracts_errors <- cook_tracts |>\n  left_join(cv_summary, by = c(\"GEOID\" = \"group_id\"))\n\n#Plot MAE across tracts\nggplot(tracts_errors) +\n  geom_sf(aes(fill = MAE), color = NA) +\n  scale_fill_viridis_c(option = \"C\", name = \"Mean Absolute Error\") +\n  labs(\n    title = \"Cross-Validated MAE by Census Tract\",\n    subtitle = \"Leave-One-Group-Out CV (Negative Binomial Model)\",\n    caption  = \"Source: City of Chicago 311 Rodent Baiting Data, 2017\"\n  ) +\n  theme_void() +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Assignment4_Sen_Sam_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n### Explanation\nTo evaluate predictive performance, the above analysis implemented a Leave-One-Group-Out Cross-Validation (LOGO-CV) using Census tracts as spatial folds. Each iteration trained the Negative Binomial model on all tracts except one and predicted the held-out tract, producing tract-level Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) values. On average, the model achieved MAE ≈ 15 and RMSE ≈ 19, indicating that predictions typically differed from observed counts by about 15 rodent requests per 500 m cell. The MAE map shows that most tracts have relatively low error (dark purple), while a few in the north and west sides exhibit higher MAE (yellow), suggesting localized variation in reporting patterns or unmodeled neighborhood effects. These are the areas where there were significant clusters of hotspots where some hotspots had extreme values. \n\n## Model Evaluation\nThe following section well compare our LOGO-CV to KDE baseline. KDE is a simple heatmap of rodent activity that spreads all the point data into a smooth \"bump\" of intensity over the city. When all these bumps overlap we get a continuous density surface. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Part 6: KDE baseline ---\n# Step 1: Setup (packages, points, boundary, window, ppp)\n\n# 1) Load required packages\n# install.packages(\"spatstat\")  # run once if not yet installed\nlibrary(spatstat)   # brings in spatstat.geom/core/etc.\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spatstat' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: spatstat.data\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spatstat.data' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: spatstat.univar\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spatstat.univar' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nspatstat.univar 3.1-4\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: spatstat.geom\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spatstat.geom' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nspatstat.geom 3.6-0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'spatstat.geom'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:MASS':\n\n    area\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: spatstat.random\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spatstat.random' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nspatstat.random 3.4-2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: spatstat.explore\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spatstat.explore' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: nlme\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'nlme'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    collapse\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nspatstat.explore 3.5-3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'spatstat.explore'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:Metrics':\n\n    auc\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: spatstat.model\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spatstat.model' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: rpart\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nspatstat.model 3.4-2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: spatstat.linnet\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'spatstat.linnet' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nspatstat.linnet 3.3-2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nspatstat 3.4-1 \nFor an introduction to spatstat, type 'beginner' \n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(dplyr)\n\n# 2) Use your existing 2017 rodent points\nrodent_sf_2017 <- rodent_sf\n\n# 3) Make sure the points are projected to meters (EPSG:3857)\nrodent_pts_3857 <- if (sf::st_is_longlat(rodent_sf_2017)) {\n  sf::st_transform(rodent_sf_2017, 3857)\n} else {\n  rodent_sf_2017\n}\n\n# 4) Create a boundary polygon from your grid\nboundary_sfc <- sf::st_union(sf::st_geometry(grid_agg_3857))   # returns sfc_MULTIPOLYGON\nboundary_sfc <- sf::st_make_valid(boundary_sfc)\n\n# 5) Convert boundary to a spatstat window\nwin_3857 <- spatstat.geom::as.owin(boundary_sfc)\n\n# 6) Convert the rodent points into a spatstat ppp (point pattern)\ncoords <- sf::st_coordinates(rodent_pts_3857)\npp <- spatstat.geom::ppp(x = coords[,1], y = coords[,2], window = win_3857)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: 729 points were rejected as lying outside the specified window\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: data contain duplicated points\n```\n\n\n:::\n\n```{.r .cell-code}\n# 7) Sanity check outputs\ncat(\"Point pattern:\", pp$n, \"events in window\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoint pattern: 50232 events in window\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Window area (sq. km):\", round(spatstat.geom::area.owin(win_3857) / 1e6, 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWindow area (sq. km): 1074 \n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Part 6: KDE baseline ---\n# Step 2: choose bandwidth, compute KDE, extract to grid, score\n\nlibrary(spatstat)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(Metrics)  # for mae(), rmse()\n\n# pp  = your point pattern (from prior step)\n# grid_agg_3857 = your fishnet with 'count' column (observed)\n\n# 1) Automatic bandwidth selection (Diggle’s method is a good default)\nbw <- bw.diggle(pp)   # you can also try: bw.ppl(pp) or bw.scott(pp)\ncat(\"Chosen bandwidth (meters):\", round(bw, 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nChosen bandwidth (meters): 2.6 \n```\n\n\n:::\n\n```{.r .cell-code}\n# 2) KDE intensity image (events per square meter)\n#    edge=TRUE applies edge correction; leaveat defaults to pixel grid\ndens_im <- density.ppp(pp, sigma = bw, edge = TRUE)\n\n# 3) Get grid centroids (to sample the KDE at each cell)\ngrid_cent <- st_centroid(grid_agg_3857)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: st_centroid assumes attributes are constant over geometries\n```\n\n\n:::\n\n```{.r .cell-code}\nxy <- st_coordinates(grid_cent)\n\n# 4) Extract KDE intensity at each centroid using nearest pixel lookup\nnp   <- spatstat.geom::nearest.pixel(xy[,1], xy[,2], dens_im)\nkde_intensity <- dens_im$v[cbind(np$row, np$col)]   # units: events per m^2\n\n# 5) Convert intensity (events/m^2) to expected count per grid cell\n#    Cell area in m^2 (assumes square fishnet in EPSG:3857)\ncell_area_m2 <- mean(as.numeric(st_area(grid_agg_3857)))\nkde_pred_count <- pmax(0, kde_intensity * cell_area_m2)  # nonnegative\n\n# 6) Score the KDE baseline against observed counts\nobs <- grid_agg_3857$count\nkde_mae  <- mae(obs, kde_pred_count)\nkde_rmse <- rmse(obs, kde_pred_count)\n\ncat(\"KDE baseline — MAE:\", round(kde_mae, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKDE baseline — MAE: 5.04 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"KDE baseline — RMSE:\", round(kde_rmse, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKDE baseline — RMSE: 9.44 \n```\n\n\n:::\n\n```{.r .cell-code}\n# (Optional) Attach to grid for mapping later\ngrid_agg_3857$kde_pred <- kde_pred_count\n```\n:::\n\n### Explanation \nTo benchmark model performance, I compared the Negative Binomial regression against a Kernel Density Estimation (KDE) baseline derived from 2017 rodent-baiting points. The KDE, which smooths event locations into a continuous density surface, achieved MAE ≈ 5 and RMSE ≈ 9 when evaluated on the same data. Although this in-sample baseline yields lower errors, it lacks predictive generalization. By contrast, the cross-validated Negative Binomial model (MAE ≈ 15, RMSE ≈ 19) provides a realistic measure of out-of-sample performance and captures interpretable spatial relationships that a KDE heatmap cannot. However, in order to draw this conclusion of model efficacy, the model must be tested on a new dataset such as 2018. \n\n## Conclusion: Discussion/Analysis \n\nThis report used 2017 Chicago 311 Rodent Baiting requests to model the spatial distribution of rodent activity using a 500 m grid. A Negative Binomial regression incorporating local spatial context (average neighbor count and distance to hot spots) effectively captured the city’s underlying spatial structure of rodent complaints. Cross-validation with Census tracts as spatial folds produced an average MAE of about 15 and RMSE of 19, indicating that model predictions typically deviated from observed counts by roughly 15 complaints per cell. The spatial distribution of errors suggested that predictive accuracy was generally consistent across most neighborhoods, with somewhat higher errors concentrated in parts of the southwest and north sides. This warrants further exploratory analysis and investigation. \n\nTo benchmark performance, the model was compared to a Kernel Density Estimation (KDE) baseline that smoothed event locations into a continuous density surface. Although the KDE baseline achieved lower in-sample error (MAE ≈ 5, RMSE ≈ 9) due to its direct use of observed event data, it lacks the ability to generalize beyond the study year or explain spatial variation through interpretable predictors. In contrast, the regression framework offers a robust, extensible foundation for spatial prediction—capable of assessing new areas or future periods—while providing insight into how neighborhood context influences rodent activity across Chicago. Temporal validation on 2018 data should be conducted as a next step to draw this conclusion. \n\n---\n\n\n",
    "supporting": [
      "Assignment4_Sen_Sam_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}