[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "This portfolio documents my learning journey in Public Policy Analytics (MUSA 5080).\n\n\nAdvanced spatial analysis and data science for urban planning and public policy.\n\n\n\n\nWeekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge\n\n\n\n\nI am originally from New York City and have worked in commercial real estate asset management for the last 5 years. I am currently a dual degree student at Penn (MBA/MUSA) and am taking Public Policy Analytics as a core requirement for the dual degree.\n\n\n\n\nEmail: [sen1@wharton.upenn.edu]\nGitHub: [@ssen-droid]"
  },
  {
    "objectID": "index.html#about-this-course",
    "href": "index.html#about-this-course",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Advanced spatial analysis and data science for urban planning and public policy."
  },
  {
    "objectID": "index.html#portfolio-structure",
    "href": "index.html#portfolio-structure",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Weekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "I am originally from New York City and have worked in commercial real estate asset management for the last 5 years. I am currently a dual degree student at Penn (MBA/MUSA) and am taking Public Policy Analytics as a core requirement for the dual degree."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Email: [sen1@wharton.upenn.edu]\nGitHub: [@ssen-droid]"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html",
    "href": "Assignments/Assignment_1/assignment_1.html",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the New York Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#scenario",
    "href": "Assignments/Assignment_1/assignment_1.html#scenario",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the New York Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#learning-objectives",
    "href": "Assignments/Assignment_1/assignment_1.html#learning-objectives",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#submission-instructions",
    "href": "Assignments/Assignment_1/assignment_1.html#submission-instructions",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#data-retrieval",
    "href": "Assignments/Assignment_1/assignment_1.html#data-retrieval",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\n\n# Clean the county names to remove state name and \"County\" \n# Hint: use mutate() with str_remove()\n\n# Display the first few rows\n\n\n# ---- 2.1 County-level data (ACS 2022 5-year) ----\nvars &lt;- c(\n  med_income = \"B19013_001\",  # Median household income\n  total_pop  = \"B01003_001\"   # Total population\n)\n\ncounty_raw &lt;- get_acs(\n  geography = \"county\",\n  variables = vars,\n  year = 2022,\n  survey = \"acs5\",\n  state = my_state,\n  output = \"wide\"\n)\n\ncounty &lt;- county_raw %&gt;%\n  mutate(\n    county = NAME %&gt;%\n      stringr::str_remove(\",\\\\s*.*$\") %&gt;%  # drop \", State\"\n      stringr::str_remove(\"\\\\s*County$\")   # drop trailing \"County\"\n  ) %&gt;%\n  select(\n    county, GEOID,\n    med_incomeE, med_incomeM,\n    total_popE,  total_popM\n  )\n\nknitr::kable(\n  head(county, 10),\n  caption = paste(\"County-level ACS (2022 5-year) for\", my_state),\n  digits = 0\n)\n\n\nCounty-level ACS (2022 5-year) for New York\n\n\ncounty\nGEOID\nmed_incomeE\nmed_incomeM\ntotal_popE\ntotal_popM\n\n\n\n\nAlbany\n36001\n78829\n2049\n315041\nNA\n\n\nAllegany\n36003\n58725\n1965\n47222\nNA\n\n\nBronx\n36005\n47036\n890\n1443229\nNA\n\n\nBroome\n36007\n58317\n1761\n198365\nNA\n\n\nCattaraugus\n36009\n56889\n1778\n77000\nNA\n\n\nCayuga\n36011\n63227\n2736\n76171\nNA\n\n\nChautauqua\n36013\n54625\n1754\n127440\nNA\n\n\nChemung\n36015\n61358\n2475\n83584\nNA\n\n\nChenango\n36017\n61741\n2526\n47096\nNA\n\n\nClinton\n36019\n67097\n2802\n79839\nNA"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#data-quality-assessment",
    "href": "Assignments/Assignment_1/assignment_1.html#data-quality-assessment",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\n\n# Create a summary showing count of counties in each reliability category\n# Hint: use count() and mutate() to add percentages\n\n\n# ---- 2.2A: compute MOE% for median income ----\ncounty_moe &lt;- county %&gt;%\n  dplyr::mutate(\n    income_moe_pct = dplyr::if_else(\n      !is.na(med_incomeE) & med_incomeE &gt; 0 & !is.na(med_incomeM),\n      100 * med_incomeM / med_incomeE,\n      NA_real_\n    )\n  )\n\n# peek at just the columns we care about\nknitr::kable(\n  county_moe %&gt;%\n    dplyr::select(county, med_incomeE, med_incomeM, income_moe_pct) %&gt;%\n    head(10),\n  caption = \"MOE% for median income (first 10 counties)\",\n  digits = c(0, 0, 0, 1)\n)\n\n\nMOE% for median income (first 10 counties)\n\n\ncounty\nmed_incomeE\nmed_incomeM\nincome_moe_pct\n\n\n\n\nAlbany\n78829\n2049\n2.6\n\n\nAllegany\n58725\n1965\n3.3\n\n\nBronx\n47036\n890\n1.9\n\n\nBroome\n58317\n1761\n3.0\n\n\nCattaraugus\n56889\n1778\n3.1\n\n\nCayuga\n63227\n2736\n4.3\n\n\nChautauqua\n54625\n1754\n3.2\n\n\nChemung\n61358\n2475\n4.0\n\n\nChenango\n61741\n2526\n4.1\n\n\nClinton\n67097\n2802\n4.2\n\n\n\n\n\n\n# ---- 2.2B: add reliability category ----\ncounty_reliability &lt;- county_moe %&gt;%\n  dplyr::mutate(\n    reliability = dplyr::case_when(\n      is.na(income_moe_pct) ~ \"Unavailable\",\n      income_moe_pct &lt; 5    ~ \"High Confidence\",\n      income_moe_pct &lt;= 10  ~ \"Moderate Confidence\",\n      income_moe_pct &gt; 10   ~ \"Low Confidence\"\n    )\n  )\n\n# quick preview\nknitr::kable(\n  county_reliability %&gt;%\n    dplyr::select(county, med_incomeE, med_incomeM, income_moe_pct, reliability) %&gt;%\n    head(10),\n  caption = \"Income MOE% + reliability category (first 10)\",\n  digits = c(0, 0, 0, 1)\n)\n\n\nIncome MOE% + reliability category (first 10)\n\n\n\n\n\n\n\n\n\ncounty\nmed_incomeE\nmed_incomeM\nincome_moe_pct\nreliability\n\n\n\n\nAlbany\n78829\n2049\n2.6\nHigh Confidence\n\n\nAllegany\n58725\n1965\n3.3\nHigh Confidence\n\n\nBronx\n47036\n890\n1.9\nHigh Confidence\n\n\nBroome\n58317\n1761\n3.0\nHigh Confidence\n\n\nCattaraugus\n56889\n1778\n3.1\nHigh Confidence\n\n\nCayuga\n63227\n2736\n4.3\nHigh Confidence\n\n\nChautauqua\n54625\n1754\n3.2\nHigh Confidence\n\n\nChemung\n61358\n2475\n4.0\nHigh Confidence\n\n\nChenango\n61741\n2526\n4.1\nHigh Confidence\n\n\nClinton\n67097\n2802\n4.2\nHigh Confidence\n\n\n\n\n\n\n# ---- 2.2C: unreliable flag + summary table ----\ncounty_reliability &lt;- county_reliability %&gt;%\n  dplyr::mutate(unreliable = income_moe_pct &gt; 10)\n\nrel_summary &lt;- county_reliability %&gt;%\n  dplyr::count(reliability) %&gt;%\n  dplyr::mutate(pct = round(100 * n / sum(n), 1)) %&gt;%\n  dplyr::arrange(match(reliability, c(\"High Confidence\",\"Moderate Confidence\",\"Low Confidence\",\"Unavailable\")))\n\nknitr::kable(rel_summary, caption = \"County reliability categories\", digits = 1)\n\n\nCounty reliability categories\n\n\nreliability\nn\npct\n\n\n\n\nHigh Confidence\n56\n90.3\n\n\nModerate Confidence\n5\n8.1\n\n\nLow Confidence\n1\n1.6"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#high-uncertainty-counties",
    "href": "Assignments/Assignment_1/assignment_1.html#high-uncertainty-counties",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\n\n# Format as table with kable() - include appropriate column names and caption\n\n\n# ---- 2.3: Top 5 counties by income MOE% ----\ntop5_uncertainty &lt;- county_reliability %&gt;%\n  dplyr::filter(!is.na(income_moe_pct)) %&gt;%                 # ignore rows where MOE% couldn't be computed\n  dplyr::arrange(dplyr::desc(income_moe_pct)) %&gt;%           # highest MOE% first\n  dplyr::slice(1:5) %&gt;%                                     # top 5\n  dplyr::transmute(                                         # select + rename for presentation\n    county,\n    `Median income ($)` = med_incomeE,\n    `Income MOE ($)`    = med_incomeM,\n    `Income MOE %`      = sprintf(\"%.1f%%\", income_moe_pct),\n     Reliability        = reliability\n  )\n\nknitr::kable(\n  top5_uncertainty,\n  caption = \"Top 5 counties by median income MOE% (ACS 2022 5-year)\"\n) %&gt;%\n  kableExtra::kable_styling(full_width = FALSE, bootstrap_options = c(\"striped\", \"hover\"))\n\n\nTop 5 counties by median income MOE% (ACS 2022 5-year)\n\n\ncounty\nMedian income ($)\nIncome MOE ($)\nIncome MOE %\nReliability\n\n\n\n\nHamilton\n66891\n7622\n11.4%\nLow Confidence\n\n\nSchuyler\n61316\n5818\n9.5%\nModerate Confidence\n\n\nGreene\n70294\n4341\n6.2%\nModerate Confidence\n\n\nYates\n63974\n3733\n5.8%\nModerate Confidence\n\n\nEssex\n68090\n3590\n5.3%\nModerate Confidence\n\n\n\n\n\nData Quality Commentary:\n[The counties that have higher % reliability are likely to benefit less from algorithmic decision making. These margins of error are too large to give us high confidence in the median income figures. Therefore, algorithms that use this data may cause harm. For example, if the state decides that counties that have &lt;$60K median income will receive social services, Hamilton looks like it’s well above this threshold but with such a high margin of error this may not be the case.]"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#focus-area-selection",
    "href": "Assignments/Assignment_1/assignment_1.html#focus-area-selection",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\n\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\n\ncounty_reliability %&gt;%\n  dplyr::select(county, med_incomeE, income_moe_pct, reliability) %&gt;%\n  dplyr::arrange(income_moe_pct)\n\n# A tibble: 62 × 4\n   county      med_incomeE income_moe_pct reliability    \n   &lt;chr&gt;             &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;          \n 1 Queens            82431           1.06 High Confidence\n 2 Suffolk          122498           1.18 High Confidence\n 3 Erie              68014           1.18 High Confidence\n 4 Kings             74692           1.27 High Confidence\n 5 Monroe            71450           1.35 High Confidence\n 6 Nassau           137709           1.39 High Confidence\n 7 Westchester      114651           1.56 High Confidence\n 8 Onondaga          71479           1.57 High Confidence\n 9 New York          99880           1.78 High Confidence\n10 Bronx             47036           1.89 High Confidence\n# ℹ 52 more rows\n\n\n\n# ---- 3.1: pick counties for tract-level study ----\nselected_counties &lt;- county_reliability %&gt;%\n  dplyr::filter(county %in% c(\"Kings\", \"Greene\", \"Hamilton\")) %&gt;%\n  dplyr::select(county, GEOID, med_incomeE, income_moe_pct, reliability)\n\nknitr::kable(\n  selected_counties,\n  caption = \"Selected counties for tract-level analysis\"\n)\n\n\nSelected counties for tract-level analysis\n\n\ncounty\nGEOID\nmed_incomeE\nincome_moe_pct\nreliability\n\n\n\n\nGreene\n36039\n70294\n6.175491\nModerate Confidence\n\n\nHamilton\n36041\n66891\n11.394657\nLow Confidence\n\n\nKings\n36047\n74692\n1.266535\nHigh Confidence\n\n\n\n\n\nComment on the output: Only one county in New York is low confidence with regard to MOE - Hamilton, NY. This is likely due to extremely small population size coupled with small sample perhaps."
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#tract-level-demographics",
    "href": "Assignments/Assignment_1/assignment_1.html#tract-level-demographics",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# ---- 3.2: Tract-level demographics (robust county naming via FIPS) ----\n\n# 1) Variables\nvars_tracts &lt;- c(\n  white_nh  = \"B03002_003\",  # White alone, not Hispanic or Latino\n  black_nh  = \"B03002_004\",  # Black alone, not Hispanic or Latino\n  hispanic  = \"B03002_012\",  # Hispanic or Latino\n  total_pop = \"B03002_001\"   # Total population\n)\n\n# 2) 3-digit county FIPS from your selected counties (5-digit GEOID -&gt; last 3)\ncounty_codes3 &lt;- stringr::str_sub(selected_counties$GEOID, -3, -1) %&gt;% unique()\n\n# 3) Pull ACS tract-level data\ntract_raw &lt;- tidycensus::get_acs(\n  geography = \"tract\",\n  variables = vars_tracts,\n  year      = acs_year,\n  survey    = \"acs5\",\n  state     = my_state,\n  county    = county_codes3,\n  output    = \"wide\"\n)\n\n# 4) Derive state/county FIPS from the tract GEOID and join to official names\n#    tract GEOID = SS + CCC + TTTTTT  (state 2, county 3, tract 6)\ntract_demo &lt;- tract_raw %&gt;%\n  dplyr::mutate(\n    state_fips  = stringr::str_sub(GEOID, 1, 2),\n    county_fips = stringr::str_sub(GEOID, 3, 5),\n    tract_label = stringr::str_extract(NAME, \"^Census Tract\\\\s*[^,]+\") %&gt;%\n                  stringr::str_remove(\"^Census Tract\\\\s*\")\n  ) %&gt;%\n  dplyr::left_join(\n    tidycensus::fips_codes %&gt;%\n      dplyr::transmute(\n        state_fips  = state_code,\n        county_fips = county_code,\n        county_label = county,   # e.g., \"Kings\"\n        state_label  = state     # e.g., \"New York\"\n      ),\n    by = c(\"state_fips\", \"county_fips\")\n  ) %&gt;%\n  # 5) Compute percentages\n  dplyr::mutate(\n    pct_white_nh = dplyr::if_else(total_popE &gt; 0, 100 * white_nhE / total_popE, NA_real_),\n    pct_black_nh = dplyr::if_else(total_popE &gt; 0, 100 * black_nhE / total_popE, NA_real_),\n    pct_hispanic = dplyr::if_else(total_popE &gt; 0, 100 * hispanicE / total_popE, NA_real_)\n  )\n\n# Quick peek\nknitr::kable(\n  tract_demo %&gt;%\n    dplyr::select(\n      GEOID, tract_label, county_label,\n      total_popE, white_nhE, pct_white_nh,\n      black_nhE, pct_black_nh,\n      hispanicE, pct_hispanic\n    ) %&gt;% head(10),\n  caption = \"Tract demographics with population percentages (first 10 rows)\",\n  digits = 1\n)\n\n\nTract demographics with population percentages (first 10 rows)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGEOID\ntract_label\ncounty_label\ntotal_popE\nwhite_nhE\npct_white_nh\nblack_nhE\npct_black_nh\nhispanicE\npct_hispanic\n\n\n\n\n36039080100\n801; Greene County; New York\nGreene County\n3230\n2866\n88.7\n59\n1.8\n168\n5.2\n\n\n36039080201\n802.01; Greene County; New York\nGreene County\n3765\n3361\n89.3\n2\n0.1\n204\n5.4\n\n\n36039080202\n802.02; Greene County; New York\nGreene County\n2641\n2048\n77.5\n176\n6.7\n145\n5.5\n\n\n36039080301\n803.01; Greene County; New York\nGreene County\n1611\n1363\n84.6\n42\n2.6\n52\n3.2\n\n\n36039080302\n803.02; Greene County; New York\nGreene County\n1424\n1240\n87.1\n15\n1.1\n78\n5.5\n\n\n36039080402\n804.02; Greene County; New York\nGreene County\n2043\n1582\n77.4\n0\n0.0\n231\n11.3\n\n\n36039080403\n804.03; Greene County; New York\nGreene County\n1273\n1254\n98.5\n0\n0.0\n19\n1.5\n\n\n36039080404\n804.04; Greene County; New York\nGreene County\n1755\n1654\n94.2\n18\n1.0\n71\n4.0\n\n\n36039080501\n805.01; Greene County; New York\nGreene County\n2726\n2551\n93.6\n27\n1.0\n98\n3.6\n\n\n36039080502\n805.02; Greene County; New York\nGreene County\n3967\n3651\n92.0\n0\n0.0\n211\n5.3"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#demographic-analysis",
    "href": "Assignments/Assignment_1/assignment_1.html#demographic-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\nFind the tract with the highest percentage of Hispanic/Latino residents Hint: use arrange() and slice() to get the top tract\nCalculate average demographics by county using group_by() and summarize() Show: number of tracts, average percentage for each racial/ethnic group\nCreate a nicely formatted table of your results using kable()\n\n# ---- 3.3A: tract with highest % Hispanic ----\ntop_hispanic_tract &lt;- tract_demo %&gt;%\n  dplyr::filter(!is.na(pct_hispanic)) %&gt;%\n  dplyr::arrange(dplyr::desc(pct_hispanic)) %&gt;%\n  dplyr::slice(1) %&gt;%\n  dplyr::select(\n    GEOID, tract_label, county_label,\n    total_popE, pct_white_nh, pct_black_nh, pct_hispanic\n  )\n\nknitr::kable(\n  top_hispanic_tract,\n  digits = c(0, 0, 0, 0, 1, 1, 1),\n  caption = \"Tract with the highest % Hispanic\"\n)\n\n\nTract with the highest % Hispanic\n\n\n\n\n\n\n\n\n\n\n\nGEOID\ntract_label\ncounty_label\ntotal_popE\npct_white_nh\npct_black_nh\npct_hispanic\n\n\n\n\n36047002000\n20; Kings County; New York\nKings County\n1899\n3.5\n2.5\n79.8\n\n\n\n\n# ---- 3.3B: summarize by county (population-weighted) ----\ncounty_summary_weighted &lt;- tract_demo %&gt;%\n  dplyr::group_by(county_label) %&gt;%\n  dplyr::summarise(\n    total_pop = sum(total_popE, na.rm = TRUE),\n    white_nh  = sum(white_nhE,  na.rm = TRUE),\n    black_nh  = sum(black_nhE,  na.rm = TRUE),\n    hispanic  = sum(hispanicE,  na.rm = TRUE),\n    n_tracts  = dplyr::n(),\n    .groups = \"drop\"\n  ) %&gt;%\n  dplyr::mutate(\n    pct_white_nh = 100 * white_nh / total_pop,\n    pct_black_nh = 100 * black_nh / total_pop,\n    pct_hispanic = 100 * hispanic / total_pop\n  ) %&gt;%\n  dplyr::select(\n    county_label, n_tracts, total_pop,\n    pct_white_nh, pct_black_nh, pct_hispanic\n  )\n\nknitr::kable(\n  county_summary_weighted,\n  digits = c(0, 0, 0, 1, 1, 1),\n  col.names = c(\"County\", \"Tracts\", \"Population\",\n                \"% White (NH)\", \"% Black (NH)\", \"% Hispanic\"),\n  caption = \"County-wide demographics (ACS 2018–2022 5-year, weighted by population)\"\n)\n\n\nCounty-wide demographics (ACS 2018–2022 5-year, weighted by population)\n\n\n\n\n\n\n\n\n\n\nCounty\nTracts\nPopulation\n% White (NH)\n% Black (NH)\n% Hispanic\n\n\n\n\nGreene County\n18\n48067\n83.8\n4.6\n6.5\n\n\nHamilton County\n4\n5090\n92.1\n1.1\n2.0\n\n\nKings County\n805\n2679620\n36.1\n28.3\n18.9"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#moe-analysis-for-demographic-variables",
    "href": "Assignments/Assignment_1/assignment_1.html#moe-analysis-for-demographic-variables",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\nCalculate MOE percentages for white, Black, and Hispanic variables Hint: use the same formula as before (margin/estimate * 100)\nCreate a flag for tracts with high MOE on any demographic variable Use logical operators (| for OR) in an ifelse() statement\nCreate summary statistics showing how many tracts have data quality issues\n\n# ---- 4.1: MOE analysis for demographic variables ----\n\n# Safety: ensure tract_demo exists\nstopifnot(exists(\"tract_demo\"))\n\ntract_moe &lt;- tract_demo %&gt;%\n  dplyr::mutate(\n    # MOE% for each group (only when estimate &gt; 0 and MOE available)\n    white_moe_pct    = dplyr::if_else(!is.na(white_nhE)  & white_nhE  &gt; 0 & !is.na(white_nhM),\n                                      100 * white_nhM  / white_nhE,  NA_real_),\n    black_moe_pct    = dplyr::if_else(!is.na(black_nhE)  & black_nhE  &gt; 0 & !is.na(black_nhM),\n                                      100 * black_nhM  / black_nhE,  NA_real_),\n    hispanic_moe_pct = dplyr::if_else(!is.na(hispanicE)  & hispanicE  &gt; 0 & !is.na(hispanicM),\n                                      100 * hispanicM  / hispanicE,  NA_real_),\n\n    # Per-group &gt;15% flags\n    over15_white = white_moe_pct    &gt; 15,\n    over15_black = black_moe_pct    &gt; 15,\n    over15_hisp  = hispanic_moe_pct &gt; 15,\n\n    # Any group over threshold\n    high_moe_flag = over15_white | over15_black | over15_hisp\n  )\n\n# Overall summary\ntract_moe_summary &lt;- tract_moe %&gt;%\n  dplyr::summarise(\n    total_tracts    = dplyr::n(),\n    high_moe_tracts = sum(high_moe_flag, na.rm = TRUE),\n    pct_high_moe    = round(100 * high_moe_tracts / total_tracts, 1),\n    # count tracts where at least one MOE% couldn't be computed\n    any_moe_na      = sum(is.na(white_moe_pct) | is.na(black_moe_pct) | is.na(hispanic_moe_pct))\n  )\n\nknitr::kable(\n  tract_moe_summary,\n  digits = 1,\n  caption = \"Summary of high-MOE tracts (ACS 2018–2022 5-year)\"\n)\n\n\nSummary of high-MOE tracts (ACS 2018–2022 5-year)\n\n\ntotal_tracts\nhigh_moe_tracts\npct_high_moe\nany_moe_na\n\n\n\n\n827\n801\n96.9\n114"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#pattern-analysis",
    "href": "Assignments/Assignment_1/assignment_1.html#pattern-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\nGroup tracts by whether they have high MOE issues. Calculate average characteristics for each group:population size, demographic percentages\nUse group_by() and summarize() to create this comparison. Create a professional table showing the pattern\n\n# ---- 4.2A: Compare tracts with vs. without high MOE issues ----\n\npattern_analysis &lt;- tract_moe %&gt;%\n  dplyr::group_by(high_moe_flag) %&gt;%\n  dplyr::summarise(\n    n_tracts         = dplyr::n(),\n    avg_pop          = mean(total_popE, na.rm = TRUE),\n    avg_pct_white    = mean(pct_white_nh, na.rm = TRUE),\n    avg_pct_black    = mean(pct_black_nh, na.rm = TRUE),\n    avg_pct_hispanic = mean(pct_hispanic, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nknitr::kable(\n  pattern_analysis,\n  digits = 1,\n  col.names = c(\"High MOE Flag\", \"Tracts\", \"Avg Pop\",\n                \"Avg % White (NH)\", \"Avg % Black (NH)\", \"Avg % Hispanic\"),\n  caption = \"Comparison of tracts with vs. without high MOE issues\"\n)\n\n\nComparison of tracts with vs. without high MOE issues\n\n\n\n\n\n\n\n\n\n\nHigh MOE Flag\nTracts\nAvg Pop\nAvg % White (NH)\nAvg % Black (NH)\nAvg % Hispanic\n\n\n\n\nTRUE\n801\n3411.7\n37.8\n27.4\n17.9\n\n\nNA\n26\n0.0\nNaN\nNaN\nNaN\n\n\n\n\n# ---- 4.2B: Count MOE&gt;15% flags by county ----\n\nflags_by_county &lt;- tract_moe %&gt;%\n  dplyr::group_by(county_label) %&gt;%\n  dplyr::summarise(\n    white_flags    = sum(over15_white,    na.rm = TRUE),\n    black_flags    = sum(over15_black,    na.rm = TRUE),\n    hispanic_flags = sum(over15_hisp,     na.rm = TRUE),\n    total_tracts   = dplyr::n(),\n    any_high_moe   = sum(high_moe_flag,   na.rm = TRUE),\n    pct_flagged    = round(100 * any_high_moe / total_tracts, 1),\n    .groups = \"drop\"\n  ) %&gt;%\n  dplyr::arrange(dplyr::desc(pct_flagged))\n\nknitr::kable(\n  flags_by_county,\n  digits = 1,\n  caption = \"Tracts with MOE% &gt; 15% by county (counts and % of tracts flagged)\"\n)\n\n\nTracts with MOE% &gt; 15% by county (counts and % of tracts flagged)\n\n\n\n\n\n\n\n\n\n\n\ncounty_label\nwhite_flags\nblack_flags\nhispanic_flags\ntotal_tracts\nany_high_moe\npct_flagged\n\n\n\n\nGreene County\n7\n14\n18\n18\n18\n100.0\n\n\nHamilton County\n2\n4\n4\n4\n4\n100.0\n\n\nKings County\n734\n706\n771\n805\n779\n96.8\n\n\n\n\n\nPattern Analysis: [In rural counties like Greene and Hamilton, ACS reliability issues fall disproportionately on minority groups: nearly every Black and Hispanic estimate is flagged as unreliable, while White estimates are more stable. In contrast, in Kings County (Brooklyn), almost every tract shows MOEs above 15% for all racial/ethnic groups (White ≈91%, Black ≈88%, Hispanic ≈96%). This demonstrates that in small-population counties, unreliability is concentrated on underrepresented groups, while in large urban counties the problem is structural to the tract-level ACS — margins of error are high across the board. For policy and algorithmic applications, this means that minority communities in rural areas risk being systematically undercounted, while in urban areas all groups are at risk of noisy estimates that could mislead algorithmic decision-making"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#analysis-integration-and-professional-summary",
    "href": "Assignments/Assignment_1/assignment_1.html#analysis-integration-and-professional-summary",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: What are the systematic patterns across all your analyses? 2. Equity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings? 3. Root Cause Analysis: What underlying factors drive both data quality issues and bias risk? 4. Strategic Recommendations: What should the Department implement to address these systematic issues?\nExecutive Summary:\nThis analysis of American Community Survey (ACS) data for New York counties reveals a striking divergence between county-level reliability and tract-level detail. At the county scale, median household income estimates are generally robust: the majority of counties fall within the “High Confidence” category (MOE &lt; 5%), and even in New York City’s Kings County the median income estimate is highly reliable. However, when we move to tract-level race and ethnicity measures, margins of error grow dramatically. Across the selected counties, nearly all tracts report at least one racial/ethnic estimate with MOE greater than 15%, demonstrating that while income data is dependable for algorithmic policy use, subgroup demographic data is far more uncertain.\nThe communities most at risk of algorithmic bias differ by geography. In rural counties such as Greene and Hamilton, small minority populations produce unstable estimates, leading to systematically unreliable data for Black and Hispanic residents. In contrast, in large urban counties like Kings, data quality issues are not confined to minority groups—margins of error are high for nearly all racial/ethnic categories. Thus, while statewide income thresholds could be applied equitably, any algorithm that targets resources based on racial composition at the tract level risks disproportionately misclassifying both rural minority communities and dense urban neighborhoods.\nThe root causes of these quality issues stem from the ACS’s design. The survey is sample-based, and smaller geographies such as census tracts often have limited sample sizes. This yields stable estimates for broadly distributed characteristics like total population or income, but highly uncertain estimates for smaller subgroups. The result is that variables most relevant to equity and inclusion—race and ethnicity—are precisely those with the least reliable data. This structural limitation increases the risk that automated decision-making systems will entrench inequities rather than reduce them.\nTo mitigate these risks, the Department should adopt a layered strategy. First, continue to use county-level median income data for resource allocation, where confidence is high. Second, treat tract-level demographic estimates with caution: use them only in conjunction with safeguards such as minimum population thresholds or higher-level geographic aggregation. Third, flag tracts where margins of error exceed set thresholds for manual review rather than algorithmic assignment. Finally, pair ACS data with supplemental sources—administrative records, local surveys, or community-based reporting—to ensure that equity-sensitive decisions are not based solely on unreliable estimates. Taken together, these measures will allow the Department to leverage ACS data responsibly while minimizing the risks of algorithmic biase"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#specific-recommendations",
    "href": "Assignments/Assignment_1/assignment_1.html#specific-recommendations",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# ---- Decision framework table (minimal + robust) ----\nlibrary(dplyr)\nlibrary(knitr)\n\ndecision_tbl &lt;- county_reliability %&gt;%\n  # keep rows where we can actually decide something\n  filter(!is.na(med_incomeE), !is.na(income_moe_pct)) %&gt;%\n  # If your data already has `reliability`, we’ll use it; otherwise derive it from MOE%\n  mutate(\n    reliability = case_when(\n      !is.na(reliability) ~ reliability,\n      income_moe_pct &lt;= 5     ~ \"High Confidence\",\n      income_moe_pct &lt;= 10    ~ \"Moderate Confidence\",\n      TRUE                    ~ \"Low Confidence\"\n    ),\n    # Map reliability -&gt; implementation recommendation\n    recommendation = case_when(\n      reliability == \"High Confidence\"      ~ \"Safe for algorithmic decisions\",\n      reliability == \"Moderate Confidence\"  ~ \"Use with caution - monitor outcomes\",\n      reliability == \"Low Confidence\"       ~ \"Requires manual review or additional data\",\n      TRUE                                  ~ \"Review needed\"\n    ),\n    # Pretty formatting for display only\n    `Median income ($)` = formatC(med_incomeE, format = \"f\", digits = 0, big.mark = \",\"),\n    `Income MOE %` = sprintf(\"%.1f%%\", income_moe_pct),\n    # Order rows by reliability (High → Moderate → Low)\n    reliability = factor(reliability, levels = c(\"High Confidence\",\"Moderate Confidence\",\"Low Confidence\"))\n  ) %&gt;%\n  transmute(\n    County = county,\n    `Median income ($)`,\n    `Income MOE %`,\n    Reliability = reliability,\n    Recommendation = recommendation\n  ) %&gt;%\n  arrange(Reliability, County)\n\nknitr::kable(\n  decision_tbl,\n  caption = \"Decision Framework for Algorithm Implementation (ACS 2022 5-year)\"\n)\n\n\nDecision Framework for Algorithm Implementation (ACS 2022 5-year)\n\n\n\n\n\n\n\n\n\nCounty\nMedian income ($)\nIncome MOE %\nReliability\nRecommendation\n\n\n\n\nAlbany\n78,829\n2.6%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nAllegany\n58,725\n3.3%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nBronx\n47,036\n1.9%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nBroome\n58,317\n3.0%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nCattaraugus\n56,889\n3.1%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nCayuga\n63,227\n4.3%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nChautauqua\n54,625\n3.2%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nChemung\n61,358\n4.0%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nChenango\n61,741\n4.1%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nClinton\n67,097\n4.2%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nColumbia\n81,741\n3.4%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nCortland\n65,029\n4.4%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nDelaware\n58,338\n3.7%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nDutchess\n94,578\n2.7%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nErie\n68,014\n1.2%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nFranklin\n60,270\n4.8%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nFulton\n60,557\n4.4%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nGenesee\n68,178\n4.6%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nHerkimer\n68,104\n4.8%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nJefferson\n62,782\n3.6%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKings\n74,692\n1.3%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLewis\n64,401\n4.2%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLivingston\n70,443\n4.0%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMadison\n68,869\n4.0%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMonroe\n71,450\n1.4%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMontgomery\n58,033\n3.6%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNassau\n137,709\n1.4%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNew York\n99,880\n1.8%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNiagara\n65,882\n2.7%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOneida\n66,402\n3.3%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOnondaga\n71,479\n1.6%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOntario\n76,603\n2.9%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOrange\n91,806\n1.9%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOrleans\n61,069\n4.9%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOswego\n65,054\n3.3%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOtsego\n65,778\n4.5%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPutnam\n120,970\n4.0%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nQueens\n82,431\n1.1%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nRensselaer\n83,734\n2.3%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nRichmond\n96,185\n2.6%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nRockland\n106,173\n2.9%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSaratoga\n97,038\n2.3%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSchenectady\n75,056\n3.0%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSchoharie\n71,479\n4.0%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSt. Lawrence\n58,339\n3.5%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSteuben\n62,506\n2.9%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSuffolk\n122,498\n1.2%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSullivan\n67,841\n4.4%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTioga\n70,427\n4.0%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTompkins\n69,995\n4.0%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nUlster\n77,197\n4.5%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nWarren\n74,531\n4.7%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nWashington\n68,703\n3.4%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nWayne\n71,007\n3.1%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nWestchester\n114,651\n1.6%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nWyoming\n65,066\n3.4%\nHigh Confidence\nSafe for algorithmic decisions\n\n\nEssex\n68,090\n5.3%\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nGreene\n70,294\n6.2%\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nSchuyler\n61,316\n9.5%\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nSeneca\n64,050\n5.2%\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nYates\n63,974\n5.8%\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nHamilton\n66,891\n11.4%\nLow Confidence\nRequires manual review or additional data\n\n\n\n\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: Counties with High Confidence median income data, such as Kings County, are appropriate for algorithmic targeting when the policy is tied to income thresholds. Median household income estimates here have margins of error well under 5%, which provides sufficient reliability for resource allocation decisions. However, even in these counties, subgroup race/ethnicity estimates should not be used as standalone inputs given their high margins of error.\nCounties requiring additional oversight: Counties with Moderate Confidence income estimates, such as Greene County, can be incorporated into algorithmic systems only with safeguards. Algorithms should flag Greene’s tracts for periodic review and be supplemented with monitoring of outcomes to ensure that borderline or unstable estimates do not result in systematic underfunding. Oversight might include comparing ACS estimates with administrative data or community-level surveys on a recurring basis.\nCounties needing alternative approaches: Counties with Low Confidence data, such as Hamilton County, should not be subject to fully automated decision-making. Here, the small population base yields large margins of error that make both income and subgroup data unreliable. Policy in these counties should rely on manual review, qualitative assessments from local agencies, or additional data collection (e.g., oversampling or local needs assessments) before allocating funds"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#questions-for-further-investigation",
    "href": "Assignments/Assignment_1/assignment_1.html#questions-for-further-investigation",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\n[List 2-3 questions that your analysis raised that you’d like to explore further in future assignments. Consider questions about spatial patterns, time trends, or other demographic factors.]\n\nSpatial patterns: Do tracts with high MOE cluster geographically (e.g., in rural versus urban areas), and how might these clusters bias statewide resource allocation?\nTime trends: How stable are ACS estimates over multiple 5-year periods, and could temporal averaging reduce the volatility of tract-level race/ethnicity estimates?\nAlternative data sources: Could administrative records (e.g., SNAP enrollment, school free-lunch participation) provide more reliable indicators of local need than ACS tract-level subgroup data?"
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#technical-notes",
    "href": "Assignments/Assignment_1/assignment_1.html#technical-notes",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Technical Notes",
    "text": "Technical Notes\nData Sources:\nU.S. Census Bureau, American Community Survey (ACS) 2018–2022 5-Year Estimates\nData retrieved using the tidycensus R package on 4.5.1\nReproducibility\nAll analysis conducted in R version [insert version, e.g., 4.3.2]\nRequired packages: tidycensus, tidyverse, knitr, stringr\nA valid Census API key is required; results can be replicated by loading the same variables and geographies for ACS 5-year 2022\nComplete code and documentation are available at: [your portfolio URL]\nMethodology Notes\nCounty-level income and population estimates were retrieved in “wide” format to simplify margin of error calculations.\nReliability categories were created using thresholds (&lt;5% = High, 5–10% = Moderate, &gt;10% = Low).\nCounties were selected for tract-level analysis to represent different reliability levels (Kings = high, Greene = moderate, Hamilton = low).\nTract-level race/ethnicity percentages were calculated by dividing group counts by total population, then multiplying by 100.\nCounty labels for tracts were assigned using official FIPS codes rather than string parsing to avoid NA parsing issues.\nHigh MOE flags were set at 15% for subgroup demographics, following common practice in ACS data quality analysis.\nLimitations\nACS estimates are based on sample surveys and are subject to sampling error; margins of error can be especially large for small populations and detailed subgroups.\nTract-level data for race/ethnicity is particularly volatile; nearly all tracts in Kings County showed MOE% &gt; 15%.\nRural counties (e.g., Hamilton) have very small populations, making subgroup estimates unreliable or unavailable.\nTemporal limitations: results are based on the 2018–2022 5-year ACS and may not reflect more recent economic or demographic shifts.\nGeographic limitations: analysis focused on New York; findings may not generalize to other states without adjustment for local context."
  },
  {
    "objectID": "Assignments/Assignment_1/assignment_1.html#submission-checklist",
    "href": "Assignments/Assignment_1/assignment_1.html#submission-checklist",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/your_file_name.html"
  },
  {
    "objectID": "Assignments/Assignment_2/Sen_Sam_Assignment2.html",
    "href": "Assignments/Assignment_2/Sen_Sam_Assignment2.html",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "",
    "text": "Learning Objectives: - Apply spatial operations to answer policy-relevant research questions - Integrate census demographic data with spatial analysis - Create publication-quality visualizations and maps - Work with spatial data from multiple sources - Communicate findings effectively for policy audiences"
  },
  {
    "objectID": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#assignment-overview",
    "href": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#assignment-overview",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "",
    "text": "Learning Objectives: - Apply spatial operations to answer policy-relevant research questions - Integrate census demographic data with spatial analysis - Create publication-quality visualizations and maps - Work with spatial data from multiple sources - Communicate findings effectively for policy audiences"
  },
  {
    "objectID": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#part-1-healthcare-access-for-vulnerable-populations",
    "href": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#part-1-healthcare-access-for-vulnerable-populations",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Part 1: Healthcare Access for Vulnerable Populations",
    "text": "Part 1: Healthcare Access for Vulnerable Populations\n\nResearch Question\nWhich Pennsylvania counties have the highest proportion of vulnerable populations (elderly + low-income) living far from hospitals?\nYour analysis should identify counties that should be priorities for healthcare investment and policy intervention.\n\n\nRequired Analysis Steps\nComplete the following analysis, documenting each step with code and brief explanations:\n\nStep 1: Data Collection (5 points)\nLoad the required spatial data: - Pennsylvania county boundaries - Pennsylvania hospitals (from lecture data) - Pennsylvania census tracts\nYour Task:\n\n# Load required packages\nlibrary(tidyverse)    \nlibrary(sf)           \nlibrary(tidycensus)   \nlibrary(tigris)"
  },
  {
    "objectID": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#part-2-comprehensive-visualization",
    "href": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#part-2-comprehensive-visualization",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Part 2: Comprehensive Visualization",
    "text": "Part 2: Comprehensive Visualization\nUsing the skills from Week 3 (Data Visualization), create publication-quality maps and charts.\n\nMap 1: County-Level Choropleth\nCreate a choropleth map showing healthcare access challenges at the county level.\nYour Task:\n\n# Create county-level access map\n# Join county summary data to county spatial boundaries\n# Filter out counties with no vulnerable tracts (to remove gray areas)\ncounties_for_map &lt;- pa_counties_projected %&gt;%\n  left_join(county_summary, by = c(\"NAMELSAD\" = \"NAMELSAD.y\")) %&gt;%\n  mutate(pct_underserved = ifelse(is.na(pct_underserved), 0, pct_underserved))\n\n# Create the map\nggplot() +\n  # County fill by percentage underserved\n  geom_sf(data = counties_for_map, \n          aes(fill = pct_underserved), \n          color = \"white\", \n          size = 0.3) +\n  # Hospital locations as points\n  geom_sf(data = hospitals_projected, \n          color = \"darkblue\", \n          size = 1.2, \n          alpha = 0.7,\n          shape = 3) +  # Shape 3 = plus sign (cross)\n  # Color scheme\n  scale_fill_gradient(low = \"lightyellow\", \n                      high = \"darkred\",\n                      name = \"% Underserved\") +\n  # Labels and theme\n  labs(title = \"Healthcare Access for Vulnerable Populations in Pennsylvania\",\n       subtitle = \"Percentage of vulnerable tracts underserved by county (+ symbols = hospitals)\",\n       caption = \"Source: 2022 ACS 5-Year Estimates, PA Hospital Data\\nVulnerable = low income (bottom 25%) + high elderly (top 25%)\\nUnderserved = &gt;15 miles from nearest hospital\") +\n  theme_void() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 11),\n    plot.caption = element_text(size = 8, hjust = 0),\n    legend.position = \"right\"\n  )\n\n\n\n\n\n\n\n\nThe above map shows the percent of vulnerable tracts that are underserved and the location of hospitals marked by the dark blue “+” symbols per the assignments instructions. As can be seen, these large counties have very few hospitals, with a 3 of them having no hospitals at all.\nHowever, the map is somewhat misleading. Many of these counties only have 1 tract that is vulnerable. This map makes could be misleading in making it seem like these whole counties are vulnerable and underserved.\n\n\n\nMap 2: Detailed Vulnerability Map\nCreate a map highlighting underserved vulnerable tracts.\nYour Task:\n\n# Map 2 with bolder vulnerable tracts\nggplot() +\n  geom_sf(data = pa_counties_projected, \n          fill = \"gray95\", \n          color = \"gray60\", \n          size = 0.5) +\n  geom_sf(data = vulnerable_tracts_projected %&gt;% filter(vulnerable == TRUE, underserved == FALSE),\n          fill = \"skyblue\",\n          color = \"blue\",  # Add outline\n          size = 0.5,\n          alpha = 0.7) +\n  geom_sf(data = vulnerable_tracts_projected %&gt;% filter(underserved == TRUE),\n          fill = \"darkred\",\n          color = \"red\",\n          size = 0.7,\n          alpha = 0.9) +\n  geom_sf(data = hospitals_projected,\n          color = \"darkgreen\",\n          size = 1.5,\n          alpha = 0.8,\n          shape = 3) +\n  labs(title = \"Underserved Vulnerable Populations in Pennsylvania\",\n       subtitle = \"Red = underserved vulnerable tracts (&gt;15 mi from hospital) | Blue = other vulnerable tracts | + = Hospitals\",\n       caption = \"Source: 2022 ACS 5-Year Estimates, PA Hospital Data\") +\n  theme_void() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10),\n    plot.caption = element_text(size = 8, hjust = 0)\n  )\n\n\n\n\n\n\n\n\nThe above map shows vulnerable tracts in light blue with a dark boarder, and vulnerable underserved tracts in dark red. As can be seen, none of the dark red tracts have a hospital in them. For Philadelphia, despite having many hospitals, there are still the highest number of vulnerable tracts.\n\n\n\nChart: Distribution Analysis\nCreate a visualization showing the distribution of distances to hospitals for vulnerable populations.\n\n# Create histogram showing distribution of distances to hospitals for vulnerable populations\nggplot(vulnerable_tracts_projected %&gt;% filter(vulnerable == TRUE), \n       aes(x = dist_to_hospital_mi)) +\n  geom_histogram(bins = 20, \n                 fill = \"steelblue\", \n                 color = \"white\", \n                 alpha = 0.8) +\n  geom_vline(xintercept = 15, \n             linetype = \"dashed\", \n             color = \"red\", \n             size = 1) +\n  annotate(\"text\", \n           x = 15.5, \n           y = Inf, \n           label = \"15 mile threshold\", \n           vjust = 1.5, \n           hjust = 0, \n           color = \"red\") +\n  labs(title = \"Distribution of Distance to Nearest Hospital for Vulnerable Tracts\",\n       x = \"Distance to Nearest Hospital (miles)\",\n       y = \"Number of Tracts\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 13, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\nThe histogram above shows that a majority of vulnerable populations live within 10 miles of hospitals. With only a few living more than 15 miles away from a hospital, qualifying them as underserved. These populations are at a very high level of risk, but many other factors in addition to distance from a hospital can put vulnerable populations at risk. Of the top 10 counties with the highest vulnerable populations, one of the counties - Clearfield - has a tract that that is also underserved.\nSuggested chart types: - Histogram or density plot of distances - Box plot comparing distances across regions - Bar chart of underserved tracts by county - Scatter plot of distance vs. vulnerable population size\nRequirements: - Clear axes labels with units - Appropriate title - Professional formatting - Brief interpretation (1-2 sentences as a caption or in text)"
  },
  {
    "objectID": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#part-3-bring-your-own-data-analysis",
    "href": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#part-3-bring-your-own-data-analysis",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Part 3: Bring Your Own Data Analysis",
    "text": "Part 3: Bring Your Own Data Analysis\nChoose your own additional spatial dataset and conduct a supplementary analysis.\n\nChallenge Options\nChoose ONE of the following challenge exercises, or propose your own research question using OpenDataPhilly data (https://opendataphilly.org/datasets/).\nNote these are just loose suggestions to spark ideas - follow or make your own as the data permits and as your ideas evolve. This analysis should include bringing in your own dataset, ensuring the projection/CRS of your layers align and are appropriate for the analysis (not lat/long or geodetic coordinate systems). The analysis portion should include some combination of spatial and attribute operations to answer a relatively straightforward question\n\n\nEducation & Youth Services\nOption A: Educational Desert Analysis - Data: Schools, Libraries, Recreation Centers, Census tracts (child population) - Question: “Which neighborhoods lack adequate educational infrastructure for children?” - Operations: Buffer schools/libraries (0.5 mile walking distance), identify coverage gaps, overlay with child population density - Policy relevance: School district planning, library placement, after-school program siting\nOption B: School Safety Zones - Data: Schools, Crime Incidents, Bike Network - Question: “Are school zones safe for walking/biking, or are they crime hotspots?” - Operations: Buffer schools (1000ft safety zone), spatial join with crime incidents, assess bike infrastructure coverage - Policy relevance: Safe Routes to School programs, crossing guard placement\n\n\n\nEnvironmental Justice\nOption C: Green Space Equity - Data: Parks, Street Trees, Census tracts (race/income demographics) - Question: “Do low-income and minority neighborhoods have equitable access to green space?” - Operations: Buffer parks (10-minute walk = 0.5 mile), calculate tree canopy or park acreage per capita, compare by demographics - Policy relevance: Climate resilience, environmental justice, urban forestry investment —\n\n\nPublic Safety & Justice\nOption D: Crime & Community Resources - Data: Crime Incidents, Recreation Centers, Libraries, Street Lights - Question: “Are high-crime areas underserved by community resources?” - Operations: Aggregate crime counts to census tracts or neighborhoods, count community resources per area, spatial correlation analysis - Policy relevance: Community investment, violence prevention strategies —\n\n\nInfrastructure & Services\nOption E: Polling Place Accessibility - Data: Polling Places, SEPTA stops, Census tracts (elderly population, disability rates) - Question: “Are polling places accessible for elderly and disabled voters?” - Operations: Buffer polling places and transit stops, identify vulnerable populations, find areas lacking access - Policy relevance: Voting rights, election infrastructure, ADA compliance\n\n\n\nHealth & Wellness\nOption F: Recreation & Population Health - Data: Recreation Centers, Playgrounds, Parks, Census tracts (demographics) - Question: “Is lack of recreation access associated with vulnerable populations?” - Operations: Calculate recreation facilities per capita by neighborhood, buffer facilities for walking access, overlay with demographic indicators - Policy relevance: Public health investment, recreation programming, obesity prevention\n\n\n\nEmergency Services\nOption G: EMS Response Coverage - Data: Fire Stations, EMS stations, Population density, High-rise buildings - Question: “Are population-dense areas adequately covered by emergency services?” - Operations: Create service area buffers (5-minute drive = ~2 miles), assess population coverage, identify gaps in high-density areas - Policy relevance: Emergency preparedness, station siting decisions\n\n\n\nArts & Culture\nOption H: Cultural Asset Distribution - Data: Public Art, Museums, Historic sites/markers, Neighborhoods - Question: “Do all neighborhoods have equitable access to cultural amenities?” - Operations: Count cultural assets per neighborhood, normalize by population, compare distribution across demographic groups - Policy relevance: Cultural equity, tourism, quality of life, neighborhood identity\n\n\n\n\nData Sources\nOpenDataPhilly: https://opendataphilly.org/datasets/ - Most datasets available as GeoJSON, Shapefile, or CSV with coordinates - Always check the Metadata for a data dictionary of the fields.\nAdditional Sources: - Pennsylvania Open Data: https://data.pa.gov/ - Census Bureau (via tidycensus): Demographics, economic indicators, commute patterns - TIGER/Line (via tigris): Geographic boundaries\n\n\nRecommended Starting Points\nIf you’re feeling confident: Choose an advanced challenge with multiple data layers. If you are a beginner, choose something more manageable that helps you understand the basics\nIf you have a different idea: Propose your own question! Just make sure: - You can access the spatial data - You can perform at least 2 spatial operations\n\n\nYour Analysis\nYour Task:\n\nFind and load additional data\n\nDocument your data source\nCheck and standardize the CRS\nProvide basic summary statistics\n\n\n\n# Load recreation centers dataset\nrec_centers &lt;- st_read(\"data/PPR_Program_Sites.geojson\")\n\nReading layer `PPR_Program_Sites' from data source \n  `C:\\Users\\16468\\OneDrive - PennO365\\Documents\\Academics\\MUSA\\Public_Policy_Analytics\\portfolio-setup-ssen-droid\\Assignments\\Assignment_2\\data\\PPR_Program_Sites.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 171 features and 10 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -75.2563 ymin: 39.90444 xmax: -74.96944 ymax: 40.12284\nGeodetic CRS:  WGS 84\n\n# Check basic information\nprint(paste(\"Number of recreation centers:\", nrow(rec_centers)))\n\n[1] \"Number of recreation centers: 171\"\n\nprint(paste(\"CRS:\", st_crs(rec_centers)$input))\n\n[1] \"CRS: WGS 84\"\n\n# Check what columns we have\nnames(rec_centers)\n\n [1] \"OBJECTID\"     \"PARK_NAME\"    \"DPP_ASSET_ID\" \"PROGRAM_TYPE\" \"SITE_CLASS\"  \n [6] \"BUILDING\"     \"GYM\"          \"LABEL_NUMBER\" \"COMMENTS\"     \"DATA_SOURCE\" \n[11] \"geometry\"    \n\n# View first few rows to understand the data\nhead(rec_centers)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -75.2563 ymin: 39.96572 xmax: -75.16713 ymax: 39.97446\nGeodetic CRS:  WGS 84\n  OBJECTID                          PARK_NAME DPP_ASSET_ID PROGRAM_TYPE\n1      807 Tiffany Fletcher Recreation Center         1911      PPR_REC\n2      808        Roberto Clemente Playground         1831      PPR_REC\n3      809              Miles Mack Playground         1910      PPR_REC\n4      810      William T Granahan Playground         1864      PPR_REC\n5      811     Francisville Recreation Center         1859      PPR_REC\n6      812          Charles A Papa Playground         1929      PPR_REC\n  SITE_CLASS BUILDING GYM LABEL_NUMBER\n1          A        Y   N         &lt;NA&gt;\n2          B        Y   N         &lt;NA&gt;\n3          A        Y   N         &lt;NA&gt;\n4          B        Y   N         &lt;NA&gt;\n5          A        Y   N         &lt;NA&gt;\n6          A        Y   N         &lt;NA&gt;\n                                                            COMMENTS\n1 Former name Mill Creek Playground and Recreation Center (12/2022).\n2                                                                   \n3                                                                   \n4                                    Located within Cobbs Creek Park\n5                                                                   \n6                                            Located in Morris Park.\n     DATA_SOURCE                   geometry\n1 Programs 11/24 POINT (-75.21582 39.96598)\n2 Programs 11/24 POINT (-75.16794 39.96572)\n3 Programs 11/24 POINT (-75.19562 39.96748)\n4 Programs 11/24  POINT (-75.2504 39.96936)\n5 Programs 11/24  POINT (-75.16713 39.9685)\n6 Programs 11/24  POINT (-75.2563 39.97446)\n\n\nI chose the Philadelphia Parks & Recreation (PPR) Program Sites dataset. This dataset contains recreation centers, playgrounds, and other youth-focused facilities operated by Philadelphia Parks & Recreation. I selected this dataset because recreation centers provide critical after-school programming, sports facilities, and community activities for children and youth, making them an important complement to the hospital access analysis from Part 1. This analysis will examine whether vulnerable populations (low-income elderly) live in areas that also lack youth educational and recreational resources.\nData source: OpenDataPhilly (Philadelphia Parks & Recreation Department). The dataset was last updated in November 2024 according to the “Programs 11/24” notation in the data source field.\nThe dataset contains 171 recreation facilities across Philadelphia.\nThe data is in WGS 84 (EPSG:4326), a geographic coordinate system. We will need to transform it (see below) to Pennsylvania South State Plane (EPSG:3365) to match the projected coordinate system used in Part 1 and enable accurate distance calculations in miles.\n\n# Transform recreation centers to Pennsylvania South State Plane (EPSG:3365)\nrec_centers_projected &lt;- rec_centers %&gt;%\n  st_transform(crs = 3365)\n\n# Check that transformation worked\nprint(paste(\"Recreation centers CRS:\", st_crs(rec_centers_projected)$input))\n\n[1] \"Recreation centers CRS: EPSG:3365\"\n\n\n\n\nResearch question\n\nDo vulnerable populations in Philadelphia have adequate access to recreation centers compared to non-vulnerable populations?\n\n\nConduct spatial analysis\n\nUse at least TWO spatial operations to answer your research question.\n\n# Filter to Philadelphia County only using GEOID\n# Philadelphia County FIPS code is 42101 (42 = PA, 101 = Philadelphia)\nphilly_tracts &lt;- pa_tracts_with_data %&gt;%\n  filter(str_starts(GEOID, \"42101\")) %&gt;%  # Filter for Philadelphia County\n  st_transform(crs = 3365) %&gt;%\n  mutate(\n    pct_elderly = (pop_65_plus_total / total_popE) * 100,\n    low_income = median_incomeE &lt; 55924,\n    high_elderly = pct_elderly &gt;= 20.1,\n    vulnerable = low_income & high_elderly\n  ) %&gt;%\n  filter(!is.na(median_incomeE))\n\n# Check how many tracts we got\nprint(paste(\"Philadelphia tracts:\", nrow(philly_tracts)))\n\n[1] \"Philadelphia tracts: 383\"\n\nprint(paste(\"Vulnerable tracts:\", sum(philly_tracts$vulnerable, na.rm = TRUE)))\n\n[1] \"Vulnerable tracts: 17\"\n\nprint(paste(\"Non-vulnerable tracts:\", sum(!philly_tracts$vulnerable, na.rm = TRUE)))\n\n[1] \"Non-vulnerable tracts: 366\"\n\n\n\n# Calculate distance for all Philadelphia tracts\nphilly_centroids &lt;- st_centroid(philly_tracts)\ndistances_to_rec &lt;- st_distance(philly_centroids, rec_centers_projected)\n\nphilly_tracts &lt;- philly_tracts %&gt;%\n  mutate(\n    dist_to_rec_ft = as.numeric(apply(distances_to_rec, 1, min)),\n    dist_to_rec_mi = dist_to_rec_ft / 5280\n  )\n\n\n# Summary statistics by vulnerability status\naccess_comparison &lt;- philly_tracts %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(vulnerable) %&gt;%\n  summarize(\n    num_tracts = n(),\n    avg_dist_to_rec = mean(dist_to_rec_mi, na.rm = TRUE),\n    median_dist_to_rec = median(dist_to_rec_mi, na.rm = TRUE),\n    pct_within_half_mile = sum(dist_to_rec_mi &lt;= 0.5, na.rm = TRUE) / n() * 100\n  )\n\nprint(access_comparison)\n\n# A tibble: 2 × 5\n  vulnerable num_tracts avg_dist_to_rec median_dist_to_rec pct_within_half_mile\n  &lt;lgl&gt;           &lt;int&gt;           &lt;dbl&gt;              &lt;dbl&gt;                &lt;dbl&gt;\n1 FALSE             366           0.371              0.335                 80.1\n2 TRUE               17           0.433              0.366                 70.6\n\n\n\n# Map showing distance colored, with vulnerable tracts outlined\nggplot() +\n  # All tracts colored by distance\n  geom_sf(data = philly_tracts,\n          aes(fill = dist_to_rec_mi),\n          color = \"white\",\n          size = 0.2) +\n  # Add thick border around vulnerable tracts\n  geom_sf(data = philly_tracts %&gt;% filter(vulnerable == TRUE),\n          fill = NA,  # No fill, just outline\n          color = \"red\",\n          size = 1.2) +  # Thick red outline\n  # Recreation centers - smaller triangles\n  geom_sf(data = rec_centers_projected,\n          color = \"darkgreen\",\n          size = 1,  # Smaller size\n          shape = 17) +\n  scale_fill_gradient(low = \"lightblue\", high = \"orange\",\n                      name = \"Distance (mi)\\nto Rec Center\") +\n  labs(title = \"Recreation Center Access in Philadelphia: Vulnerable vs Non-Vulnerable Tracts\",\n       subtitle = \"Red outline = Vulnerable tracts | Green triangles = Recreation Centers\",\n       caption = \"Source: Philadelphia Parks & Recreation, 2022 ACS\\nVulnerable = low income + high elderly population\") +\n  theme_void() +\n  theme(\n    plot.title = element_text(size = 13, face = \"bold\"),\n    plot.subtitle = element_text(size = 10),\n    plot.caption = element_text(size = 8, hjust = 0),\n    legend.position = \"right\"\n  )\n\n\n\n\n\n\n\n\nInterpretation:\nThe analysis reveals modest disparities in recreation center access between vulnerable and non-vulnerable populations in Philadelphia. Vulnerable tracts are located an average of 0.43 miles from the nearest recreation center compared to 0.37 miles for non-vulnerable tracts, and only 70.6% of vulnerable tracts fall within a half-mile walking distance compared to 80.1% of non-vulnerable tracts. While these differences suggest that vulnerable populations may have slightly worse access to recreational facilities, further statistical testing would be necessary to determine whether these observed differences are statistically significant or could be attributed to random chance. A permutation test or similar randomization procedure would help establish whether the 0.06-mile average difference and the 9.5 percentage point gap in coverage represent meaningful disparities requiring policy intervention. Overall, both groups demonstrate relatively good access to recreation centers, with most Philadelphia tracts located within comfortable walking distance of these facilities."
  },
  {
    "objectID": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#finally---a-few-comments-about-your-incorporation-of-feedback",
    "href": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#finally---a-few-comments-about-your-incorporation-of-feedback",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Finally - A few comments about your incorporation of feedback!",
    "text": "Finally - A few comments about your incorporation of feedback!\nThis time around I tried to format a little better and delete extraneous lines, such as “Your Task” and various instructions. I kept some of the instructions for ease of review as necessary."
  },
  {
    "objectID": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#submission-requirements",
    "href": "Assignments/Assignment_2/Sen_Sam_Assignment2.html#submission-requirements",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Submission Requirements",
    "text": "Submission Requirements\nWhat to submit:\n\nRendered HTML document posted to your course portfolio with all code, outputs, maps, and text\n\nUse embed-resources: true in YAML so it’s a single file\nAll code should run without errors\nAll maps and charts should display correctly\n\n\nFile naming: LastName_FirstName_Assignment2.html and LastName_FirstName_Assignment2.qmd"
  }
]